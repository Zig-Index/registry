{
  "name": "datastar.http.zig",
  "owner": "zigster64",
  "repo": "datastar.http.zig",
  "description": "Alternate Datastar API for http.zig",
  "type": "project",
  "topics": [
    "data-star",
    "datastar",
    "hypermedia",
    "zig-package"
  ],
  "stars": 11,
  "forks": 2,
  "watchers": 0,
  "updated_at": "2025-12-05T10:00:25Z",
  "dependencies": [
    {
      "name": "httpz",
      "url": "git+https://github.com/karlseguin/http.zig#2965722dcf9fd656f218fdbd76f4ced0f376bd0d",
      "hash": "httpz-0.0.0-PNVzrLwlBwCjuWNaokqbQwrsstWT3c_4yb-8TNuYOFcZ"
    },
    {
      "name": "logz",
      "url": "git+https://github.com/karlseguin/log.zig?ref=master#cc5268932e84da9dad09fd48b544d67212889c02",
      "hash": "logz-0.0.0-O9YWXrJKAgBA98lbuTKXADVOR1ULzRGLMzrj1dkduNAF"
    },
    {
      "name": "tokamak",
      "url": "git+https://github.com/cztomsik/tokamak?ref=main#a8010432a642298461e98c7d90d737247feeaeb5",
      "hash": "tokamak-2.0.0-FbnSeVOmBgC_0KOptR5fHV4GBxw1zqdx9ZqFzVUTl22W"
    }
  ],
  "minimum_zig_version": "0.15.1",
  "readme": "# Datastar lib for http.zig\n\nA Zig library that conforms to the Datastar SDK specification.\n\nhttps://github.com/starfederation/datastar/blob/develop/sdk/ADR.md\n\n.. and passes the official test cases.\n\nThis SDK uses streams all the way down, so there is no implicit extra allocations.\n\nVersions :\n- Datastar 1.0.0-RC6\n- Zig 0.15.2\n\nIt uses the latest \"writergate\" changes for zig 0.15.2, and makes good use of the high speed buffered \ninterfaces. The SDK is very fast, and very lightweight.\n\nExample apps provided with\n- http.zig\n- tokamak\n- (more to follow)\n\n# Future Updates\n\nFuture updates to this repo will include support for Zig stdlib http server, as well as \nother popular HTTP server libs, such as zzz, zio, and zap.\n\nWill provide example apps that demonstrate using this SDK with each of these frameworks \nas they get ported.\n\nOnce this lib is fully generic across multiple frameworks, I will rename it to `datastar.zig` to reflect that.\n\n\n# Audience and Scope\n\nWho is this repo for ?\n\n- Anyone interested in using Datastar. https://data-star.dev.\n\nIt is a state of the art Hypermedia-first library for building apps. \n\nIts not \"yet another frontend framework\" - its a 10kb JS shim that allows you to write application code\nat the backend, and leverage modern browser standards to have a very fast, very light, reactive UI \nwith none of the junk. There are no build steps, no npm deps - just declarative HTML and reactive signals,\ndriven from the backend.\n\nIf you know, you know.\n\nIt uses a well defined SSE-first protocol that is backend agnostic - you can use the the same simple \nSDK functions to write the same app in Go, Clojure, C#, PHP, Python, Bun, Ruby, Rust, Lisp, Racket, Java, etc. \n\nThis project adds Zig to that list of supported SDK languages.\n\nIt uses the exact same spec as all the other SDK's, and reads extremely similarly to say - a Go program\nor a Python program using the same SDK.\n\nWhy consider the Zig version then ? Who is that for ?\n\n- Existing Zig programmers who want to try Datastar\n- Datastar app builders who want to experiment with performance, and dabble in new backend languages\n\nConsider Zig if every microsecond counts, or you want stupidly small memory footprints that dont grow.\n\nZig gives you some pretty good tuning options if you want to chase benchmarks and break records too.\n\nWe are talking orders of magnitude performance and resource usage gains for your existing Datastar app, depending\non what you are currently using. \n\nTry it out.\n\n# Quick Shot Introduction\n\nIf you just want to quickly install this, and try out the demo programs first, do this :\n\n```\n... get zig 0.15.2 installed on your machine\ngit clone https://github.com/zigster64/datastar.http.zig\ncd datastar.http.zig\nzig build\n./zig-out/bin/example_1\n```\n\nThen open your browser to http://localhost:8081\n\n\nThis will bring up a kitchen sink app that shows each of the SDK functions in use in the browser, with a \nsection that displays the code to use on your backend to drive the page you are looking at.\n\n![Screenshot of example_1](./docs/images/example_1.png)\n\n`./zig-out/bin/tokamak_basic` - Same application, but using Tokamak instead of directly using http.zig\n\n---\n\nTo run the additional example apps, try\n\n`./zig-out/bin/example_2` - a simple cat auction site.\nBring up multiple browser windows and watch the bids get updated in realtime to all windows.\n\n![Screenshot of example_2](./docs/images/example_2.png)\n\n---\n\n`./zig-out/bin/example_22` - a more complex cat aution site, with session based preferences managed at the backend.\nBring up multiple browser windows and watch the bids get updated in realtime to all windows.\nChange preferences, and watch that all browser windows in the same session get their preferences updated.\n\nUse a different machine, or browser, or use the 'Profiles' feature in Chrome/Safari/Firefox to simulate a new session.\nNote that the bids update in realtime across all browsers, and just the preferences changes are sticky across all \nwindows belonging to the same machine/profile.\n\n![Screenshot of example_22](./docs/images/example_22.png)\n\n---\n\n`./zig-out/bin/example_5` - an excellent and exciting multi-player farming simulator, where users can plant and attend \nto various crops to help them grow to harvest (or whither and die if neglected)\n\n![Screenshot of example_5](./docs/images/example_5.png)\n\n# Validation Test\n\nWhen you run `zig build`, it will compile several apps into `./zig-out/bin` including a binary called `validation-test`\n\nRun `./zig-out/bin/validation-test`, which will start a server on port 7331\n\nThen follow the procedure documented at\n\nhttps://github.com/starfederation/datastar/blob/main/sdk/tests/README.md\n\nTo run the official Datastar validation suite against this test harness\n\nThe source code for the `validation-test` program is in the file `tests/validation.zig`\n\nCurrent version passes all tests.\n\n# Contrib Policy\n\nAll contribs welcome.\n\nPlease raise a github issue first before adding a PR, and reference the issue in the PR title. \n\nThis allows room for open discussion, as well as tracking of issues opened and closed.\n\n\n# Example Apps\n\nWhen you run `zig build` it will compile several apps into `./zig-out/bin/` to demonstrate using different parts \nof the api\n\nUsing http.zig :\n\n- example_1  shows using the Datastar API using basic SDK handlers\n- example_2  shows an example multi-user auction site for cats with realtime updates using pub/sub\n- example_22 Same cat auction as above, but with per-user preferences, all handled on the backend only\n\n<!-- - example_3  shows an example multi-user pigeon racing betting site with realtime updates -->\n<!-- - example_4  shows an example multi-game, multi-player TicTacToe site, using the backstage actor framework -->\n\n- example_5  shows an example multi-player Gardening Simulator using pub/sub\n\nUsing Tokamak :\n\n- tokamak_basic  shows using the Datastar API using basic SDK handlers (same as example_1, but with Tokamak)\n\n<!-- Using zig stdlib http server : -->\n\nTODO :\n\n- Jetzig examples\n- Zig stdlib examples\n- Zio+stdlib examples\n- zzz examples\n- zap examples\n- backstage (actor framework) examples\n\n\n<!-- - example_10 as per example_1, but using zig stdlib instead of http.zig -->\n\n\n# Installation and Usage\n\nTo build an application using this SDK\n\n1) Add datastar.http.zig as a dependency in your `build.zig.zon`:\n\n```bash\nzig fetch --save=\"datastar\" \"git+https://github.com/zigstser64/datastar.http.zig#master\"\n```\n\n2) In your `build.zig`, add the `datastar` module as a dependency you your program:\n\n```zig\nconst datastar = b.dependency(\"datastar\", .{\n    .target = target,\n    .optimize = optimize,\n});\n\n// the executable from your call to b.addExecutable(...)\nexe.root_module.addImport(\"datastar\", datastar.module(\"datastar\"));\n```\n\n\n# Functions\n\n## Cheatsheet of all SDK functions\n\n```zig\nconst datastar = @import(\"datastar\");\n\n// read signals either from GET or POST\ndatastar.readSignals(comptime T: type, req: anytype) !T\n\n// set the connection to SSE, and return an SSE object\nvar sse = datastar.NewSSE(req, res) !SSE\n\n// patch elements function variants\nsse.patchElements(self: *SSE, elements: []const u8, opt: PatchElementsOptions) !void\nsse.patchElementsFmt(self: *SSE, comptime elements: []const u8, args: anytype, opt: PatchElementsOptions) !void\nsse.patchElementsWriter(self: *SSE, opt: PatchElementsOptions) *std.Io.Writer \n\n// patch signals function variants\nsse.patchSignals(self: *SSE, value: anytype, json_opt: std.json.Stringify.Options, opt: PatchSignalsOptions) !void\nsse.patchSignalsWriter(self: *SSE, opt: PatchSignalsOptions) *std.Io.Writer\n\n// execute scripts function variants\nsse.executeScript(self: *SSE, script: []const u8, opt: ExecuteScriptOptions) !void\nsse.executeScriptFmt(self: *SSE, comptime script: []const u8, args: anytype, opt: ExecuteScriptOptions) !void \nsse.executeScriptWriter(self: *SSE, opt: ExecuteScriptOptions) *std.Io.Writer\n\n// variants of getting an SSE object\n\n// create SSE with custom buffer\nvar sse = NewSSEBuffered(req, res, buffer) !SSE \n// create an SSE object from an existing open connection\nvar sse = NewSSEFromStream(stream: std.net.Stream, buffer: []u8) SSE\n// fine tune internal IO buffering / other configuration\ndatastar.configure(.{ .buffer_size = 255 });\n\n// SDK extension - auto pub/sub management\napp.subscribe(\"topic\", sse.stream, someCallbackFunction);\napp.subscribeSession(\"topic\", sse.stream, someCallbackFunction, SessionID);\napp.publish(\"topic\");\napp.publishSession(\"topic\", SessionID); // only publish to subs with this sessionID\n```\n\n# Using the Datastar SDK\n\n## The SSE Object\n\nCalling NewSSE, passing a request and response, will return an object of type SSE.\n\n```zig\n    pub fn NewSSE(req, res) !SSE \n```\n\nThis will configure the connnection for SSE transfers, and provides an object with Datastar methods for\npatching elements, patching signals, executing scripts, etc.\n\nWhen you are finished with the SSE object, you should either :\n\n- Call `sse.close()` if you are done and want to close the connection as part of your handler.\n\n- Otherwise, the SSE connection is left open after you exit your handler function. In this case, you can \n  access the `sse.stream: std.net.Stream` value and store it somewhere for additional updates over that open connection. \n\n- This Zig SDK also includes a simple Pub/Sub subsystem that takes care o  tracking open connections in a convenient manner, or you can use the value `sse.stream` to roll your own as well. \n\n\n\n## Reading Signals from the request\n\n```zig\n    pub fn readSignals(comptime T: type, req: anytype) !T\n```\n\nWill take a Type (struct) and a HTTP request, and returns a filled in struct of the requested type.\n\nIf the request is a `HTTP GET` request, it will extract the signals from the query params. You will see that \nyour GET requests have a `?datastar=...` query param in most cases. This is how Datastar passes signals to\nyour backend via a GET request.\n\nIf the request is a `HTTP POST` or other request that uses a payload body, this function will use the \npayload body to extract the signals. This is how Datastar passes signals to your backend when using POST, etc.\n\nEither way, provide `readSignals` with a type that you want to read the signals into, and it will use the\nrequest method to work out which way to fill in the struct.\n\nExample :\n```zig\n    const FooBar = struct {\n        foor: []const u8,\n        bar: []const u8,\n    };\n\n    const signals = try datastar.readSignals(FooBar, req);\n    std.debug.print(\"Request sent foo: {s}, bar: {s}\\n\", .{signals.foo, signals.bar});\n```\n\n\n## Patching Elements\n\nThe SDK Provides 3 functions to patch elements over SSE.\n\nThese are all member functions of the SSE type that NewSSE(req, res) returns.\n\n\n```zig\n    pub fn patchElements(self: *SSE, elements: []const u8, opt: PatchElementsOptions) !void\n\n    pub fn patchElementsFmt(self: *SSE, comptime elements: []const u8, args: anytype, opt: PatchElementsOptions) !void\n\n    pub fn patchElementsWriter(self: *SSE, opt: PatchElementsOptions) *std.Io.Writer \n```\n\nUse `sse.patchElements` to directly patch the DOM with the given \"elements\" string.\n\nUse `sse.patchElementsFmt` to directly patch the DOM with a formatted print (where elements,args is the format string + args).\n\nUse `sse.patchElementsWriter` to return a std.Io.Writer object that you can programmatically write to using complex logic.\n\nIf using the Writer, then be sure to call `sse.flush()` when you are finished writing to it and wish to keep the socket open, and writing to the same patchElements stream later.\n\nCalling `sse.close()` will automatically flush the writer output.\n\nStarting any new patchElements / patchSignals / executeScript on the SSE object will automatically flush the last writer as well.\n\n\nPatchElementsOptions is defined as :\n\n```zig\npub const PatchElementsOptions = struct {\n    mode: PatchMode = .outer,\n    selector: ?[]const u8 = null,\n    view_transition: bool = false,\n    event_id: ?[]const u8 = null,\n    retry_duration: ?i64 = null,\n};\n\npub const PatchMode = enum {\n    inner,\n    outer,\n    replace,\n    prepend,\n    append,\n    before,\n    after,\n    remove,\n};\n```\n\nSee the Datastar documentation for the usage of these options when using patchElements.\n\nhttps://data-star.dev/reference/sse_events\n\nMost of the time, you will want to simply pass an empty tuple `.{}` as the options parameter. \n\nExample handler (from `examples/01_basic.zig`)\n\n```zig\nfn patchElements(req: *httpz.Request, res: *httpz.Response) !void {\n    var sse = try datastar.NewSSE(req, res);\n    defer sse.close();\n\n    try sse.patchElementsFmt(\n        \\\\<p id=\"mf-patch\">This is update number {d}</p>\n    ,\n        .{getCountAndIncrement()},\n        .{},\n    );\n}\n```\n\n## Patching Signals\n\nThe SDK provides 2 functions to patch signals over SSE.\n\nThese are all member functions of the SSE type that NewSSE(req, res) returns.\n\n```zig\n    pub fn patchSignals(self: *SSE, value: anytype, json_opt: std.json.Stringify.Options, opt: PatchSignalsOptions) !void\n\n    pub fn patchSignalsWriter(self: *SSE, opt: PatchSignalsOptions) *std.Io.Writer\n```\n\nPatchSignalsOptions is defined as :\n```zig\npub const PatchSignalsOptions = struct {\n    only_if_missing: bool = false,\n    event_id: ?[]const u8 = null,\n    retry_duration: ?i64 = null,\n};\n```\n\nUse `patchSignals` to directly patch the signals, passing in a value that will be JSON stringified into signals.\n\nUse `patchSignalsWriter` to return a std.Io.Writer object that you can programmatically write raw JSON to.\n\nExample handler (from `examples/01_basic.zig`)\n```zig\nfn patchSignals(req: *httpz.Request, res: *httpz.Response) !void {\n    var sse = try datastar.NewSSE(req, res);\n    defer sse.close();\n\n    const foo = prng.random().intRangeAtMost(u8, 0, 255);\n    const bar = prng.random().intRangeAtMost(u8, 0, 255);\n\n    try sse.patchSignals(.{\n        .foo = foo,\n        .bar = bar,\n    }, .{}, .{});\n}\n```\n\n## Executing Scripts\n\nThe SDK provides 3 functions to initiate executing scripts over SSE.\n\n```zig\n\n    pub fn executeScript(self: *SSE, script: []const u8, opt: ExecuteScriptOptions) !void\n\n    pub fn executeScriptFmt(self: *SSE, comptime script: []const u8, args: anytype, opt: ExecuteScriptOptions) !void \n\n    pub fn executeScriptWriter(self: *SSE, opt: ExecuteScriptOptions) *std.Io.Writer\n```\n\nExecuteScriptOptions is defined as :\n```zig\npub const ExecuteScriptOptions = struct {\n    auto_remove: bool = true, // by default remove the script after use, otherwise explicity set this to false if you want to keep the script loaded\n    attributes: ?ScriptAttributes = null,\n    event_id: ?[]const u8 = null,\n    retry_duration: ?i64 = null,\n};\n```\n\nUse `executeScript` to send the given script to the frontend for execution.\n\nUse `executeScriptFmt` to use a formatted print to create the script, and send it to the frontend for execution. \nWhere (script, args) is the same as print(format, args).\n\nUse `executeScriptWriter` to return a std.Io.Writer object that you can programmatically write the script to, for\nmore complex cases.\n\nExample handler (from `examples/01_basic.zig`)\n```zig\nfn executeScript(req: *httpz.Request, res: *httpz.Response) !void {\n    const value = req.param(\"value\"); // can be null\n\n    var sse = try datastar.NewSSE(req, res);\n    defer sse.close();\n\n    try sse.executeScriptFmt(\"console.log('You asked me to print {s}')\"\", .{\n            value orelse \"nothing at all\",\n    });\n}\n```\n\n# Advanced SSE Topics\n\n## SSE IO, buffering and async socket writes\n\nSince Zig 0.15, IO and buffering are now a big deal, and offers some extreme options for fine tuning and optimizing your systems.  This is a good thing, and lots of fun to experiment with.\n\nThe SSE object uses a std.Io.Writer stream to convert normal HTML Element, Signal and Script updates into the Datastar protocol, and then write them to the browser's connection.\n\nBy default this std.Io.Writer uses a zero-sized intermediate buffer, so every chunk written is passed straight through to the underlying socket writer after being converted to Datastar protocol.\n\nWith http.zig, this underlying socket writer is already buffered, and uses async IO to drain data to the user's browser in the background after your handler exits. This is all taken care of for you.\n\nFor most applications, these defaults offer an excellent balance between performance and memory consumption.\n\nFor advanced use cases, you can opt in for applying buffering to the SSE operations as well, by setting a default buffer size. \n\nThis will reduce the number of writes between the SSE processor and the underlying http.zig writer to the browser, at the expense of one extra allocation per request.\n\nTo configure buffering, use this : \n\n```zig\n    datastar.configure(.{ .buffer_size = 255 }); // or whatever value you want\n```\n\nIf your handlers are typically doing a large number of small writes inside a patchElements operation, then its definitely worth thinking about using a buffer for this.\n\nIf you are using formatted printing a lot (either through `w.print(...) or sse.patchElementsFmt(...)`), then that will generate a larger number of small writes as well, as the print \nformatter likes to output fragments of your string, and each argument all as separate write operations.\n\nThe performance differences between using a buffer or not can be quite marginal (we are talking microseconds if at all), but its there if you think you need it. \n\nIf you choose to use this, try and set the size of the buffer around the size of your most common smaller outputs, which could be 200-300 bytes depending on your application, or it could be a lot more.\n\nFor example - if you set the buffer size to 200, then write 500 bytes to it, you will end up with 3 writes to the underlying stream - 1 for each time the buffer is full, then 1 more to flush the remainder.\n\nThe SDK automatically takes care of flushing these intermediate buffers for you.\n\nBenchmark, experiment, and make your own decision about whether buffering improves your app or not, and use what works best for you.\n\n## Using custom buffering for a specific SSE object\n\nIn some rare cases, you may want to apply a custom buffer to the SSE stream outside of the default configuration.\n\nUse \n\n```zig\n    pub fn NewSSEBuffered(req, res, buffer) !SSE \n```\n\nFor example - see `fn code()` in `examples/01_basic.zig`, where it provides its own buffer to the SSE object, where the size is calculated in advance based on the size \nof the payload.\n\nThis is because the `code()` fn uses a tight loop that writes 1 byte at a time to the output. \nThis custom sized buffer allows the whole output  bnto be written into memory before being passed on to the socket writer.\n\nConsider using this if you have a rare case that makes sense.\n\n# Publish and Subscribe\n\nThis Zig SDK includes an easy to use Pub/Sub system for use with Datastar.\n\nIt is useful for running \"multiplayer\" apps, where you want to use long lived SSE connections, and broadcast application \nstate changes to a large number of connected clients.\n\nThis is sometimes also referred to as the CQRS pattern.\n\nUsing this builtin pub/sub system in the Zig SDK is optimized for both of the following use cases :\n\n- Where you have a few thousand concurrent connections each subscribed to a handful of topics\n- Where you have a few thousand different topics, each with a handful of connections\n\nInternally, we use a pair of indexes to ensure that both extremes of how topics and connections are arranged remain \nperformant.\n\nA cheap shared-CPU VPS will be good enough for about 2000 concurrent users no problems, where each connection receives a patchElement update every second.\n\nWe have tested this on a bare metal cloud hosted machine with 6 core / 12 thread, and its OK for up to 48,000\nconcurrent connections, each being updated every second.\n\nIn both cases, its a network bottleneck, not a CPU / memory bottleneck.  \n\nIf you want to stretch beyond that, then you start running into \"Production Scale Problems\", and should look at a more\n\"Production Scale\" pub/sub message bus, such as Nats, Redis Pub/Sub, Postgres Notify, Rabbit MQ, Kafka, etc.\n\n\"Production Scale\" means :\n\n- Where you expect to run your application over multiple instances (even for failover sanity) - then you need an industrial message bus anyway\n- Where you expect to have way more than 40,0000 concurrent connections on a good day\n\nBe aware of these limits if using the built in pub/sub\n\nPlease read through some of the examples in the `examples` directory to see this being used in practice. \nThere is a lot of documentation below, which might be a bit daunting, but its dead easy to use once you \nsee whats going on.\n\n## Using Pub/Sub - 1) Create a Subscribers object\n\nFirst thing you need to do is create a `datastar.Subscribers` object, and store this in your global scope.\n\nUse this function from the datastar package to create a Subscribers object\n\n```zig\n    // create a Subscribers type, passing a parent Context type \n    // The Context type used in the same way as when you create a httpz.Server(Ctx: type)\n    // and is typically the same value\n    pub fn Subscribers(comptime Context: type) type\n\n    // Then initialize an instance of this type using init(std.mem.Allocator)\n```\n\nFor a complete example of setting this up, have a look at `examples/02_petshop.zig`\nwhich follows this basic outline :\n\n```zig\n// define our global 'App' context type\npub const App = struct {\n    gpa: Allocator,\n    subscribers: datastar.Subscribers(*App), // <--- define the Type\n\n    pub fn init(gpa: Allocator) !*App {\n        const app = try gpa.create(App);\n        app.* = .{\n            .gpa = gpa,\n            .subscribers = try datastar.Subscribers(*App).init(gpa, app), // <--- create the instance\n        };\n        return app;\n    }\n}\n\n// then define the App as the global context in our main function\npub fn main() !void {\n    var gpa = std.heap.DebugAllocator(.{}).init;\n    const allocator = gpa.allocator();\n\n    // Create the global App context here, which contains a Subscribers object, as above\n    var app = try App.init(allocator); \n    defer app.deinit();\n\n    // Create the HTTP server, which also uses *App as the context\n    // and stores the value of the app instance in the server\n    var server = try httpz.Server(*App).init(allocator, .{\n        .port = PORT,\n        .address = \"0.0.0.0\",\n    }, app);\n}\n\n// So now all our HTTP handler functions now take a *App as the 1st param\n// with the value set to global *App context\nfn index(_: *App, _: *httpz.Request, res: *httpz.Response) !void {\n    res.content_type = .HTML;\n    res.body = @embedFile(\"index.html\");\n}\n```\n\nAs long as you already understand how contexts work in `http.zig`, then this should look familiar.\n\nIf not, dont worry, copy the examples provided in the repo to get a working starting point.\n\nThats the hard part out the way !!  \n\nOnce you have that setup, its all extremely simple from here on.\n\n## Pub/Sub - 2) Subscribing to a topic\n\nIn any of your handlers, once you have an SSE stream, you can use this to subscribe to a topic :\n```zig\n    pub fn subscribe(self: *Self, topic: []const u8, stream: std.net.Stream, func: CallbackFn) !void\n```\n\nThe `topic` param is a simple string.\n\nThe `stream` param is the `std.net.Stream` value of the connected stream.\n\nThe `func: Callback` param is the fn ptr to the callback function that gets invoked when `topic` is \npublished to.\n\n\nExample of subscribing - from `examples/02_petshop.zig`\n```zig\n// User hits GET /cats\n// This creates a long lived SSE connection, and subscibes it to the \"cats\" topic\n// When \"cats\" topic is updated, the App.publishCatList callback gets called\nfn catsList(app: *App, req: *httpz.Request, res: *httpz.Response) !void {\n    const sse = try datastar.NewSSE(req, res);\n    try app.subscribe(\"cats\", sse.stream, App.publishCatList);\n}\n```\n\nThe signature the `Callback function` is determined by how you initially defined your `Subscribers` object.\n\nIf you used, for example `Subscribers(*App)` then the `Callback function` looks like\n\n```zig\n  fn (ctx: *App, stream: std.net.Stream, session: SessionType)\n```\n\nIf you used, for example `Subscribers(void)` then the `Callback function` looks like\n\n```zig\n  fn (stream: std.net.Stream)\n```\n\n## Pub/Sub - 3) Publishing to a topic\n\nIn your app, you will receive events that change the application state (such as POST requests), at which \npoint you want to update all connected clients that these changes affect.\n\nYou do this by broadcasting by topic.\n\nUse this function to broadcast by topic :\n```zig\n  pub fn publish(self: *Self, topic: []const u8) !void \n```\n\nExample (from `examples/02_petshop.zig`)\n```zig\n// User hits POST /bids, which updates application state\n// and triggers an broadcast on the cats topic\nfn postBid(app: *App, req: *httpz.Request, _: *httpz.Response) !void {\n    const id_param = req.param(\"id\").?;\n    ... do stuff to update the Application state\n    app.cats.items[id].bid = new_bid;\n\n    // update any screens subscribed to the \"cats\" topic\n    try app.publish(\"cats\");\n}\n```\n\nThere is also a variant of publish where you only want to publish to subscribers with a specific \nSession. This is used in `examples/022_petshop.zig` for example, when setting user preferences \nthen it only publishes an update to it's own session, not the whole world.\n\n```zig\n  pub fn publishSession(self: *Self, topic: []const u8, session: SessionType) !void \n```\n\nKeep reading to see what happens now when the callback is invoked, and do the broadcast\nusing `publishCatList`\n\n\n## Pub/Sub - 4) Writing the Callback function\n\nIn your callback function where you want to publish a result to an existing open SSE connection,\nyou will first need to get an SSE object from that open stream.\n\nAll callback functions will provide this existing open stream as a parameter.\n\nYou can then use this SSE object to patchElements / patchSignals / executeScripts, etc\n\nUse this function, which takes an existing open std.net.Stream, and an optional buffer to use for writes.\n\n(ie - you can set it to the empty buffer &.{} for an unbuffered writer).\n\n\n```zig\n    pub fn NewSSEFromStream(stream: std.net.Stream, buffer: []u8) SSE\n```\n\nIf using this method, you MUST use `sse.flush()` when you are finished.\n\nSimplifed Example, from `examples/02_cats.zig` in the `publishCatList` function :\n\n```zig\npub fn publishCatList(app: *App, stream: std.net.Stream, _: ?[]const u8) !void {\n\n    // get an SSE object for the given stream\n    var buffer: [1024]u8 = undefined;\n    var sse = datastar.NewSSEFromStream(stream, &buffer);\n\n    // Set the sse to PatchElements, and return us a writer\n    var w = sse.patchElementsWriter(.{});\n\n    // setup a grid to display the cats in\n    try w.writeAll(\n        \\\\<div id=\"cat-list\" class=\"grid grid-cols-3>\n    );\n\n    // each cat object can render itself to the given writer\n    for (app.cats.items) |cat| {\n        try cat.render(w);\n    }\n\n    // finish the original grid\n    try w.writeAll(\n        \\\\</div>\n    );\n\n    try sse.flush(); // dont forget to flush !\n```\n\n## Pub/Sub - 5) Using Sessions with Pub/Sub\n\nWhen you publish updates to a topic to all subscribers ... you dont always want to send the exact same content to\nevery subscriber.\n\nYou still want to broadcast to everyone on the same topic, but you also want to tailor the published output on a\nuser-by-user basis in this case.\n\nWe can do that by using a unique \"Session Value\", and attaching that to each subscription.\n\nSo use this variant when you want to associate a Session ID with a subscription :\n```zig\n    pub fn subscribeSession(self: *Self, topic: []const u8, stream: std.net.Stream, func: Callback, session: SessionType) !void \n```\n\nSo now, in your Callback function, there is an extra paramater passed at the end called `session`\n\nIf this not null, then you can use it to uniquely tailor the generated output to match what the user prefs are \nconnected to that session.\n\nFor a comprehensive example of this, look at `examples/022_petshop.zig  / 022_cats.zig`\n\nThis variant of the Cat Aution site allows the user to set preferences for how they want the Cats list to be \ndisplayed - like by Highest Price / Most Recent Bid, etc.\n\nThis preferences state is stored completely on the backend, and uses session cookies to segregate users, and \nthen generate something slightly different for each user on every `broadcast(\"cats\")`\n\nNote - the point of this example is to demonstrate how to tailor output per subscriber on a broadcast ... nothing more than that.\n\n\n## Pub/Sub internals, memory management, handling dropouts and reconnects\n\nInternally, the Subscriber struct uses a few clever data structures.\n\nEach individual Subscription is defined as :\n```zig\n    const Subscription = struct {\n        stream: std.net.Stream,\n        action: Callback(T),\n        session: SessionType = null,\n    };\n```\n\nAnd then holds 2 indexes\n\nSubscriptions - which is a map[topic_name] -> [Subscription]\n\nThis is used so that when publishing to a topic, the system can quickly get a list of all subscribers to that topic\nto write to.  This index keeps things fast when there is a large number of topics with a handful of subscribers.\n\nStreamTopicMap - which is a map[stream] -> [topics]\n\nThis is used so that when given a stream, you can quickly see which topics it is subscribed to. This is important\nwhen a write to a stream fails, the system then needs to un-subscribe that stream / remove it from the Subscriptions\nlist. Having the exact topic list means its much faster finding which Subscriptions need to be culled.\n\nThese are defined as \n```zig\n    // A map keyed on topic, giving a list of Subscriptions connected\n    const Subscriptions = std.StringHashMap(std.ArrayList(Subscription));\n\n    // A map keyed on Stream, giving a list of topics subscribed to\n    const StreamTopicMap = std.AutoHashMap(std.net.Stream, std.ArrayList([]const u8));\n```\n\nDuring a publish event, if there is any write error to the stream, then that Stream is considered \"dead\", and\nadded to a list of \"dead connections\".  After looping through the publish operation, the \"dead connections list\" is \nthen purged from the subscription lists.\n\nThe backend doesnt reliably get to see when users drop out, except when it comes to writing to that connection\nand getting back a write error (typically error.NotOpenForWriting).\n\nSo basically, on every broadcast event, the system will automatically detect lost connections, and trim down\nits subscriber list.\n\nLikewise when a user re-connects, this is just seen as a new connection, and they are appended to the list\nof subscribers by stream and topic.  On subscription, the system will do some sanity checks to ensure\nthat connections cannot have multiple subscriptions to the same topic.\n",
  "owner_avatar_url": "https://avatars.githubusercontent.com/u/72305366?u=cf46defe1dc7db6770201913a79150fbcbddb6ff&v=4",
  "releases": [
    {
      "tag_name": "0.15.2-RC6",
      "name": "0.15.2-RC6",
      "body": "This release works with Zig 0.15.2 and Datastar v1.0.0-RC6\r\n\r\nIncludes several improvements to the Cat auction\r\n\r\nStill assumes http.zig\r\n\r\nTODO list :\r\n- Make it generic using comptime reflection (not tied to http.zig, no dependencies)\r\n- Add examples for Tokamak, Jetzig, zzz, zio and stdlib servers\r\n\r\nWhen its generic enough to work across multiple frameworks, will rename the whole repo to \r\ndatastar.zig",
      "prerelease": false,
      "published_at": "2025-10-30T01:46:36Z",
      "html_url": "https://github.com/zigster64/datastar.http.zig/releases/tag/0.15.2-RC6",
      "assets": []
    },
    {
      "tag_name": "0.15.1",
      "name": "0.15.1",
      "body": "Snapshot that works with zig 0.15.1\r\n\r\nMinimal set of changes needed to get this working with 0.15.1 and http.zig\r\n\r\nUses no buffering in the intermediate writers \r\n\r\nWill do a big refactor next to make the whole lib conform to the official Datastar ADR, and at that point will stretch this new Io.Writer framework so that the user can specify intermediate buffering if they want\r\n\r\nNote that the current `drain` function will need updating to handle this, as it's supposed to suck bytes from the buffer before consuming the data passed.  This will take a bit of fiddling and tuning yet\r\n",
      "prerelease": false,
      "published_at": "2025-09-14T02:27:23Z",
      "html_url": "https://github.com/zigster64/datastar.http.zig/releases/tag/0.15.1",
      "assets": []
    },
    {
      "tag_name": "0.14",
      "name": "0.14",
      "body": "Snapshot of master that works with Zig 0.14 and http.zig",
      "prerelease": false,
      "published_at": "2025-09-07T00:49:00Z",
      "html_url": "https://github.com/zigster64/datastar.http.zig/releases/tag/0.14",
      "assets": []
    }
  ],
  "owner_bio": "Half Stack Dev.\r\n\r\nIâ€™m into minimalist code and tools.\r\n\r\n\r\n",
  "owner_company": null,
  "owner_location": "Outback Australia, middle of nowhere",
  "owner_blog": null,
  "owner_twitter_username": null,
  "owner_followers": 53,
  "owner_following": 56,
  "owner_created_at": "2020-10-03T12:46:34Z",
  "license": "MIT",
  "category": "library"
}