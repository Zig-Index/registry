{
  "name": "datastor.zig",
  "owner": "zigster64",
  "repo": "datastor.zig",
  "description": "Data persistence library for Zig",
  "type": "package",
  "topics": [
    "zig-package"
  ],
  "stars": 4,
  "forks": 0,
  "watchers": 1,
  "updated_at": "2025-11-23T21:24:17Z",
  "minimum_zig_version": "0.12.0",
  "readme": "# datastor.zig\n\nFast & Light Data persistence layer for Zig\n\n## Version Log\n\n- Dec 2023 - v0.0.0 - init project\n- Jan 2024 - v0.2.0 - new key types (serial / uuid / string)\n\n## Intended use is for:\n\n- Object persistence using local storage, for edge / IoT / local game world, etc\n- Thread safe for use in a single process only\n- Persist Table, Timeseries and Tree structured data\n- Situations where using an external DB would be overkill\n- Where performance is more important than general flexibility\n\nOn disk format uses S2S format for object storage\n(see https://github.com/ziglibs/s2s)\n\nS2S is battle tested code, but it does lack a few types that it can serialize out of the box. You can code around this\neasy enough, but its something you should be aware of.\n\n--- \n\n## Not intended for :\n\n- Any situation where the entire dataset will not fit in memory\n- Scalable, multi-process database backends.\n- General Purpose data persistence. Datastor has a highly opinionated approach to dealing with Static vs Timeseries data. That may not suit the way your data is structured.\n- Current data format uses native `usize` quite a bit, so the datafiles are not 100% portable between machines with different word sizes.\n\nFor any of the \"Not Intended\" use cases above, best look at options such as SQLite, DuckDB for embedded DBs\nor server based PostgreSQL w/ TimeseriesDB extensions over the network.\n\nReferences:\n\n- [Postgres Libraries for Zig](http://github.com/karlseguin/pg.zig)\n- [DuckDB Libraries for Zig](http://github.com/karlseguin/zuckdb.zig)\n- [SQLite for Zig](https://github.com/search?q=language:zig%20sqlite&type=repositories)\n- [MySQL for Zig](https://github.com/search?q=language:zig%20mysql&type=repositories)\n- [Redis for Zig](https://github.com/search?q=language:zig%20redis&type=repositories)\n\n----\n\n## Project Scope - how it works\n\n`datastor.zig` provides an embedded \"Object Persistence\" API for collections of Zig Types.\n\nIn concept, A Datastor is a light comptime wrapper around your struct, that provides :\n\n- An ordered HashMap collection of elements, synched to disk\n- CRUD operations against that collection\n- A single 'primary key' stored as extra metadata against the user-supplied struct\n- Primary Keys can be one of : (Serial Number, UUID, Custom String)\n- Timeseries extension, to provide each record in a Table with an unlimited audit trail of state transitions\n- Timeseries handy functions to get element state at a point in time / events over a period, etc\n- Handles tagged union data, so each table may store multiple variants of a type, but still using a strict schema across types\n- Handles Tree structured data, so you can optionally overlay a heirachy on top of your collection\n- Utility functions for tree data to reparent nodes, or move nodes up and down within their parent block\n\nThe example directory contains a large number of example scenarios, datastores, and reports.\n\nThe wiki contains a structured walk through tutorial for how to use the different datastore types.\n\n---\n\n# Types of Datastore\n\n## [Table Data](#table-data)\n\nFor 2D Tables, where each row is an instance of your data struct, with additional metadata to record the key, etc.\n\nExample: A Table of Customer information.\n\n## [Tree Data](#tree-data)\n\nFor Tree structured data, where each row is an instance of your data struct, with additional metadata that references the parent row.\n\nExample: A Tree of Projects within a Heirachy of Projects\n\n## [Timeseries Data](#timeseries-data)\n\nFor streaming / event / state transition data, where each row is an instance of your event data, with additional metadata to \nreference the parent record, and a timestamp for when the record was created.\n\nExample: Lets say we have a game, with a Table of 'Monster'.  We can add a Timeseries datastore, which tracks the (x,y) location and current HitPoints\nof any Monster at each turn in the game. This keeps the original Monster table un-modified, and tracks an audit trail of state transitions for \nall monsters in a separate timeseries array.\n\n---\n\n# Operations on a Datastore\n\n| Function | Description | Notes |\n|---|---|---|\n| load() | Loads the Datastore from disk | |\n| save() | Saves the Datastore to disk | |\n| items() []Record | Returns an ordered ArrayList of all items in the datastore | Caller owns the ArrayList, must free() after use |\n| append(Value) Key | Add an item to the datastore. Will compute a new primary key for the record | Returns the value of the newly computed primary key for the new record |\n| put(Key, Value) | Updates the Value of the record with the given Key ||\n| get(Key) Record | Returns the record with the given Key ||\n| delete(Key) | Deletes the record with the given Key | \"Deleted\" Records are kept on disk, but marked as invalid |\n| vacuum() | Vacuum will strip out all deleted records from the datastore, and re-number the SERIAL primary keys, plus any referenced records in Timeseries datastores ||\n| select(filterFn) []Record | Returns an ordered ArrayList of all the items that match the given filter. The filter is a function that takes the record value, and returns true if it matches | Caller owns the ArrayList, and must free() after use |\n| migrate(OldStruct, NewStruct) | Converts existing datastores from the old record structure to a new record structure ||\n\n\n\n---\n\n# Types of Keys\n\n## SERIAL\n\nTables with a SERIAL primary key. \n\nWhen a new record is added to a Table, it automatically gets assigned to (NUMBER OF RECORDS + 1)\n\n## UUID\n\nUUID primary keys generate a new random UUIDv4 value when new records are created\n\n## String\n\nA String key is a custom user-generated key for new records\n\nThe owning structure must define a function to generate a new key based on the record contents, and the record number\n\nFor Table datastores :\n`pub fn newID(self, allocator, record_number) []const u8`\n\nFor Tree datastores, optionally include this function :\n\n`pub fn newNodeID(self, allocator, parent_key, record_number, sibling_count) []const u8`\n... or fallback to `newID()` if newNodeID() is not provided\n\n\n---\n\n\n# Table Data\n\nA Table is a collection of records, where each record is mapped to a Zig struct, and has a unique KEY that identifies that record.\n\nRecords are stored on disk in insert order, and retrieving all the records from the store are also in the original insert order.\n\nCreate a Table type:\n\n|Function| Description | Notes |\n|--------|-------------|-------|\n| Table(ItemType) type | Returns a new type, representing a Table datastore, with a SERIAL key ||\n| TableWithKey(ItemType, KeyType) type | Returns a new type, representing a Table datastore, with the specified KEY type | KEY can be one of .serial, .uuid, .string |\n\nInit / Deinit a Table:\n\n|Function| Description | Notes |\n|--------|-------------|-------|\n| init(allocator, filename) !Table | Returns a new instance of a Table, with the associated file ||\n| deinit() | Frees up memory allocated by the table. This includes memory allocated for each record | If the base struct for the store includes a `free(allocator)`, this will be called on each record |\n\nTable specific operations\n\n|Function| Description | Notes |\n|--------|-------------|-------|\n| append(ItemType) !KeyType | Appends a new record to the store. Returns the value of the generated key | The new records are NOT saved to disk, until save() is called on the store, to allow updates to be batched. |\n\n---\n\n# Tree Data\n\nCreate a Tree type\n\n|Function| Description | Notes |\n|--------|-------------|-------|\n| Tree(ItemType) type | Returns a new type, representing a Tree datastore, with a SERIAL key ||\n| TreeWithKey(ItemType, KeyType) type | Returns a new type, representing a Tree datastore, with the specified KEY type | KEY can be one of .serial, .uuid, .string |\n\n\nInit / Deinit a Tree:\n\n|Function| Description | Notes |\n|--------|-------------|-------|\n| init(allocator, filename) !Table | Returns a new instance of a Table, with the associated file ||\n| deinit() | Frees up memory allocated by the table. This includes memory allocated for each record | If the base struct for the store includes a `free(allocator)`, this will be called on each record |\n\nTable specific functions. All the functions that are available to a Table also apply to a Tree.\n\nTree specific operations\n\n|Function| Description | Notes |\n|--------|-------------|-------|\n| putNode(parent_key, key, value) !void ||\n\n--- \n\n## Timeseries Data\n\n---\n\n---\n\n# Everything from here down needs to be rewritten / deleted\n\n\n\n\n## Intial State information vs State Transitions\n\nDatastor takes a highly opinionated approach to separating data persistence between \"Static\" data, and \"Timeseries\" data.\n\nStatic data is for :\n- Initial State data / config / assets\n- May be updated occassionally after initial boot\n- Static data is explicitly loaded and saved to and from disk using functions `table.load()` and `table.save()`\n- There is no per-record disk I/O. `load()` loads the whole table from disk, and `save()` saves the whole table to disk\n\nTimeseries data is for :\n- Recording state transitions in the static data, after system start\n- Timestamped audit trail of events for each element of static data\n- Timeseries data is loaded on `table.load()`, and automatically appended to disk on every `table.addEvent(Event)`\n- Disk I/O is per record - everytime a new timeseries event is added\n\n\nThe API considers that the initial state of an Item, and its collection of events over time, form a single Coherent Entity with a single logical API.\n\nOn disk, its splits these into 2 files - 1 file for the initial Static data, that is only occassionally updated (if ever), and 1 other file for the timeseries / event \ndata, that is frequently appended to.\n\nThe Datastor API then wraps this as a single storage item.\n\n---\n# Wrapped DataType\n\nFor any given struct T, the datastor will maintain a collection of \n\nItemType(T)\n\nWhich is a wrapper around your original struct T.\n\nThis ItemType(T) wrapper includes extra fields such as the unique ID of this record, the ID of the parent record, etc.\n\nExample - creating a datastor on this type :\n```zig\nconst MyDataType = struct {\n  x: usize,\n  y: usize,\n}\n```\n\nusing Key type `usize`, will create a wrapper object around MyDataType that adds an `id` field of type usize, and several extra convenience functions.\n\nie\n```zig\nstruct {\n  id: usize,\n  value: MyDataType,\n}\n```\n\nWhen you `put()` or `append()` to the datastor, you pass in `MyDataType`\n\nWhen you `get()` or iterate over the `items()` in the datastor, you get back the Wrapped type, so you have access to the \nunique ID associated with your original data.\n\nie:\n```zig\nfor (db.items()) |item| {\n   std.debug.print(\"Item with ID {d}:\", .{item.id});\n   std.debug.print(\"Value: {}\\n\", .{item.value});\n}\n```\n---\n\nTODO - rewrite from here down\n\n\n# API Overview\n\n## For Static-only data :\n\n| Function | Description |\n|----------|-------------|\n| Table(comptime K:type, comptime T:type) |  Returns a Table object that wraps a collection of (struct) T<br><br>T must have a function `free()` if it contains fields that are allocated on load (such as strings) | \n| table.init(Allocator, filename: []const u8) | Initialises the Table |\n| table.deinit()                              | Free any memory resources consumed by the Table |\n| | |\n| table.load() !void                          | Explicitly load the collection from disk |\n| table.save() !void                          | Explicitly save the data to disk |\n| | |\n| table.items() []Item                          | Returns a slice of all the items in the Table, in insertion order |\n| table.get(id) ?Item                            | Gets the element of type T, with the given ID (or null if not found) |\n| | |\n| table.put(T)                                | Add or overwrite element of type T to the Table. Does not write to disk yet. Batch up many updates, then call `save()` once | \n| table.append(T) usize  (Autoincrement !)          | Adds a new element of type T to the table, setting the ID of the new record to the next value in sequence. Returns the new ID<br><br>If the base type has a function `newID(count: usize) KeyType`, then it uses that to get the next Key value |\n\n\nAutoincrement note - Datatsor calculates the 'next sequence' as `Table.len + 1`, which is quick and simple enough. \nIf loading data into a datastor, then use one method or the other, but avoid mixing them together, as the ID forms the key in the hashtable.\n\n## For Static + Timeseries data :\n\n| Function | Description |\n|----------|-------------|\n| TableWithTimeseries(comptime T:type, comptime EventT: type) |  Returns a Table object that wraps a collection of (struct) T, with an unlimited array of EventT events attached<br><br>T must have a field named `id:usize` that uniquely identifies the record<br>T must have a function `free()` if it contains fields that are allocated on load (such as strings)<br><br>EventT must have a field named `parent_id:usize` and `timestamp:i64` | \n| table.init(Allocator, table_filename: []const u8, event_filename: []const u8) | Initialises the Table  |\n| table.deinit()                              | Free any memory resources consumed by the Table |\n| | |\n| table.load() !void                          | Explicitly load the collection from disk |\n| table.save() !void                          | Explicitly save the data to disk |\n| | |\n| table.items() []T                          | Returns a slice of all the items in the Table, in insertion order |\n| table.get(id) ?T                           | Gets the element of type T, with the given ID (or null if not found) |\n| | |\n| table.put(T)                                | Add or overwrite element of type T to the Table. Does not write to disk yet. Batch up many updates, then call `save()` once | \n| table.append(T) usize  (Autoincrement !)          | Adds a new element of type T to the table, setting the ID of the new record to the next value in sequence. Returns the new ID |\n| | |\n| Timeseries Functions | |\n| table.eventCount() usize                    | How many events all up ? |\n| table.eventCountFor(id: usize) usize       | How many events for the given element ?|\n| | |\n| table.getAllEvents() []EventT               | Get all the events for all elements in this datastor, in timestamp order |\n| table.getEventsBetween(from, to: i64) ArrayList(EventT) | Get an ArrayList of all events between to 2 timestamps.<br><br>Caller owns the list and must `deinit()` after use |\n| table.getEventsFor(id: usize) ArrayList(EventT) | Get an ArrayList for all events asssociated with this element in the datastor.<br><br>Caller owns the List and must `deinit()` after use |\n| table.getEventsForBetween(id: usize, from, to: i64) ArrayList(EventT) | Get an ArrayList of all events for element matching ID, between to 2 timestamps.<br><br>Caller owns the list and must `deinit()` after use |\n| | |\n| table.addEvent(event)                       | Add the given event to the collection. Will append to disk as well as update the events in memory |\n| table.latestEvent(id: usize)               | Get the latest event for element matching ID |\n| table.eventAt(id: usize, timestamp: i64)   | Get the state of the element matching ID at the given timestamp. Will return the event that is on or before the given timestamp |\n\n\n## Tree / Heirachy Table Support\n\nIn order to be treated as a tree, elements of the Table must have a field `parent_id: usize`\n\nFor Tagged Union types, the tagged union must provide 2 functions `getParentID() usize` and `setParentID(usize)` \n\n| Function | Description |\n|----------|-------------|\n| getChildren(parent_id) ArrayList(T) | Returns an ArrayList(T) of child nodes with this parent.<br><br>Caller owns the ArrayList and must `deinit()` after use |\n\n---\n# Table data Examples\n\n## Define a Cat struct that can be used as a Datastor\n\n```zig\nconst Cat = struct {\n    id: usize = 0,\n    breed: []const u8,\n    color: []const u8,\n    length: u16,\n    aggression: f32,\n\n    const Self = @This();\n\n    // struct must supply a free() function for the datastor to manage cleaning up memory allocations\n    pub fn free(self: Self, allocator: std.mem.Allocator) void {\n        allocator.free(self.breed);\n        allocator.free(self.color);\n    }\n}\n```\n\n## Load a Datastor based on our Cat struct\n\n```zig\npub fn load_simple_table() !void {\n    const gpa = std.heap.page_allocator;\n\n    var catDB = try datastor.Table(Cat).init(gpa, \"db/cats.db\");\n    defer catDB.deinit();\n    try catDB.load();\n\n    // print out all the cats \n    for (catDB.items() |cat| {\n        std.debug.print(\"Cat {d} is a {s} {s}, that is {d} inches long, with an aggression rating of {:.2f}\\n\", .{\n            cat.id,\n            cat.color,\n            cat.breed,\n            cat.length,\n            cat.aggression,\n        });\n    }\n\n    // update one of the cats to be more aggressive, and save the datastor\n    var my_cat = catDB.get(2) orelse return;\n    my_cat.aggression += 0.1;\n    catDB.put(my_cat);\n    catDB.save();\n}\n```\n\nproduces output:\n```zig\nCat 0 is ID: 1 Breed: Siamese Color: white Length: 30, Aggression Factor: 7.00e-01\nCat 1 is ID: 2 Breed: Burmese Color: grey Length: 24, Aggression Factor: 6.00e-01\nCat 2 is ID: 3 Breed: Tabby Color: striped Length: 32, Aggression Factor: 5.00e-01\nCat 3 is ID: 4 Breed: Bengal Color: tiger stripes Length: 40, Aggression Factor: 9.00e-01\n```\n\n--- \n\n# Timeseries data Examples\n\nSo far so good. Our virtural world is now populated with a group of cats.\n\nHowever, our cats (when they are not sleeping), like to get up and move around.\n\nWe need to track where are cats are and what they are doing.\n\nBut we dont want to have to keep overwritting state information against our Cats everytime something happens.\n\nWe can get around this by adding Timeseries data to each Cat. Timeseries data is a fast append-only, timestamped record\nof events that tracks what happens with a Cat at a point in time.\n\nUsing a Timeseries log, we keep the original state information about all our cats in a pristine condition, and can use\nthe timeseries data to quickly work out what state any Cat is in at a point in time.\n\n## Example - define Timeseries / Event data for each Cat\n\n```zig\n// A timeseries record of events that are associated with a cat\nconst CatEvent = struct {\n    parent_id: usize = 0, // parent_id is the ID of the Cat that this event belongs to\n    timestamp: i64,\n    x: u16,\n    y: u16,\n    attacks: bool,\n    kills: bool,\n    sleep: bool,\n    description: []const u8,\n\n    const Self = @This();\n\n    // events struct must also supply a free() function for the datastor to manage cleaning up memory allocations\n    // since the event contains a string \"description\" that is allocated on demand.\n    pub fn free(self: Self, allocator: std.mem.Allocator) void {\n        allocator.free(self.description);\n    }\n}\n```\n\n## Example - Load Cats+Timeseries data, and run several different reports\n\n```zig\npub fn cats_with_timeseries_data() !void {\n    const gpa = std.heap.page_allocator;\n\n    // use TableWithTimeseries - give it 2 struct types\n    // one for the static info on the Cat, and the other to store events\n    var catDB = try datastor.TableWithTimeseries(Cat, CatEvent).init(\n      gpa,\n      \"db/cats.db\",\n      \"db/cats.events\",\n    );\n    defer catDB.deinit();\n\n    // load both the base table, and all the events for all cats\n    try catDB.load();\n\n    // print out all the events in timestamp order\n    std.debug.print(\"All events for all cats in timestamp order:\\n\", .{});\n    for (catDB.getAllEvents()) |event| {\n        std.debug.print(\"{s}\", .{event});\n    }\n\n    // now print out Cats in the datastor,\n    // along with an audit trail of events for each cat\n    std.debug.print(\"\\nAll cats with full audit trail:\\n\", .{});\n    for (catDB.items()) |cat| {\n        std.debug.print(\"Cat {s}\\n\", .{cat});\n        const events = try catDB.getEventsFor(cat.id);\n        defer events.deinit();\n        for (events.items) |event| {\n            std.debug.print(\"  - At {d}: {s} -> moves to ({d},{d}) status: (Asleep:{any}, Attacking:{any})\\n\",\n            .{\n               event.timestamp, event.description,\n               event.x, event.y,\n               event.sleep, event.attacks,\n            });\n        }\n    }\n\n    // iterate through 4 timestamps and show the state of all cats at the given timestamp\n    for (0..4) |i| {\n        const t = i * 10 + 1;\n        std.debug.print(\"\\nState of all cats at Timestamp {d}\\n\", .{t});\n        for (catDB.items()) |cat| {\n            if (catDB.eventAt(cat.id, @intCast(t))) |e| {\n                std.debug.print(\"  - {s} {s} since {d} at ({d},{d}) status: (Asleep: {any}, Attacking: {any})\\n\",\n                .{\n                  cat.breed,\n                  e.description,\n                  e.timestamp,\n                  e.x, e.y,\n                  e.sleep,\n                  e.attacks,\n                });\n            } else unreachable;\n        }\n    }\n\n    // get the latest status for each cat\n    std.debug.print(\"\\nCurrent state of all cats, based on latest event for each\\n\", .{});\n    for (catDB.items()) |cat| {\n        const e = catDB.latestEvent(cat.id).?;\n        std.debug.print(\"  - {s} is currently doing - {s} since {d} at ({d},{d}) status: (Asleep: {any}, Attacking: {any})\\n\",\n            .{\n                cat.breed,\n                e.description,\n                e.timestamp,\n                e.x, e.y,\n                e.sleep,\n                e.attacks,\n            });\n    }\n}\n```\n\nproduces output :\n```zig\nParentID: 1 Timestamp: 1 At 10,10  Attacks: false Kills false Sleeps true Comment: starts at Location\nParentID: 2 Timestamp: 1 At 20,10  Attacks: false Kills false Sleeps true Comment: starts at Location\nParentID: 3 Timestamp: 1 At 10,20  Attacks: false Kills false Sleeps true Comment: starts at Location\nParentID: 4 Timestamp: 1 At 20,20  Attacks: false Kills false Sleeps true Comment: starts at Location\nParentID: 1 Timestamp: 10 At 10,10  Attacks: false Kills false Sleeps false Comment: awakes\nParentID: 1 Timestamp: 20 At 20,10  Attacks: true Kills false Sleeps false Comment: attacks Burmese\nParentID: 2 Timestamp: 21 At 20,10  Attacks: false Kills false Sleeps false Comment: awakes\nParentID: 3 Timestamp: 21 At 10,20  Attacks: false Kills false Sleeps false Comment: awakes\nParentID: 2 Timestamp: 25 At 20,10  Attacks: true Kills false Sleeps false Comment: retaliates against Siamese\nParentID: 3 Timestamp: 29 At 10,20  Attacks: false Kills false Sleeps true Comment: goes back to sleep\nParentID: 4 Timestamp: 30 At 20,20  Attacks: false Kills false Sleeps false Comment: awakes from all the commotion\nParentID: 4 Timestamp: 40 At 20,10  Attacks: true Kills false Sleeps false Comment: attacks Burmese and Siamese\n\nAll cats with full audit trail:\nCat ID: 1 Breed: Siamese Color: white Length: 30, Aggression Factor: 7.00e-01\n  - At 1: starts at Location -> moves to (10,10) status: (Asleep:true, Attacking:false)\n  - At 10: awakes -> moves to (10,10) status: (Asleep:false, Attacking:false)\n  - At 20: attacks Burmese -> moves to (20,10) status: (Asleep:false, Attacking:true)\nCat ID: 2 Breed: Burmese Color: grey Length: 24, Aggression Factor: 6.00e-01\n  - At 1: starts at Location -> moves to (20,10) status: (Asleep:true, Attacking:false)\n  - At 21: awakes -> moves to (20,10) status: (Asleep:false, Attacking:false)\n  - At 25: retaliates against Siamese -> moves to (20,10) status: (Asleep:false, Attacking:true)\nCat ID: 3 Breed: Tabby Color: striped Length: 32, Aggression Factor: 5.00e-01\n  - At 1: starts at Location -> moves to (10,20) status: (Asleep:true, Attacking:false)\n  - At 21: awakes -> moves to (10,20) status: (Asleep:false, Attacking:false)\n  - At 29: goes back to sleep -> moves to (10,20) status: (Asleep:true, Attacking:false)\nCat ID: 4 Breed: Bengal Color: tiger stripes Length: 40, Aggression Factor: 9.00e-01\n  - At 1: starts at Location -> moves to (20,20) status: (Asleep:true, Attacking:false)\n  - At 30: awakes from all the commotion -> moves to (20,20) status: (Asleep:false, Attacking:false)\n  - At 40: attacks Burmese and Siamese -> moves to (20,10) status: (Asleep:false, Attacking:true)\n\nState of all cats at Timestamp 1\n  - Siamese starts at Location since 1 at (10,10) status: (Asleep: true, Attacking: false)\n  - Burmese starts at Location since 1 at (20,10) status: (Asleep: true, Attacking: false)\n  - Tabby starts at Location since 1 at (10,20) status: (Asleep: true, Attacking: false)\n  - Bengal starts at Location since 1 at (20,20) status: (Asleep: true, Attacking: false)\n\nState of all cats at Timestamp 11\n  - Siamese awakes since 10 at (10,10) status: (Asleep: false, Attacking: false)\n  - Burmese starts at Location since 1 at (20,10) status: (Asleep: true, Attacking: false)\n  - Tabby starts at Location since 1 at (10,20) status: (Asleep: true, Attacking: false)\n  - Bengal starts at Location since 1 at (20,20) status: (Asleep: true, Attacking: false)\n\nState of all cats at Timestamp 21\n  - Siamese attacks Burmese since 20 at (20,10) status: (Asleep: false, Attacking: true)\n  - Burmese awakes since 21 at (20,10) status: (Asleep: false, Attacking: false)\n  - Tabby awakes since 21 at (10,20) status: (Asleep: false, Attacking: false)\n  - Bengal starts at Location since 1 at (20,20) status: (Asleep: true, Attacking: false)\n\nState of all cats at Timestamp 31\n  - Siamese attacks Burmese since 20 at (20,10) status: (Asleep: false, Attacking: true)\n  - Burmese retaliates against Siamese since 25 at (20,10) status: (Asleep: false, Attacking: true)\n  - Tabby goes back to sleep since 29 at (10,20) status: (Asleep: true, Attacking: false)\n  - Bengal awakes from all the commotion since 30 at (20,20) status: (Asleep: false, Attacking: false)\n\nCurrent state of all cats, based on latest event for each\n  - Siamese is currently doing - attacks Burmese since 20 at (20,10) status: (Asleep: false, Attacking: true)\n  - Burmese is currently doing - retaliates against Siamese since 25 at (20,10) status: (Asleep: false, Attacking: true)\n  - Tabby is currently doing - goes back to sleep since 29 at (10,20) status: (Asleep: true, Attacking: false)\n  - Bengal is currently doing - attacks Burmese and Siamese since 40 at (20,10) status: (Asleep: false, Attacking: true)\n```\n\n---\n\n# Union Datatype Example\n\n## Define a Union that can be used in a datastor\n\n```zig\nconst AnimalType = enum { cat, dog };\n\nconst Animal = union(AnimalType) {\n    const Self = @This();\n\n    cat: cats.Cat,\n    dog: dogs.Dog,\n\n    // Union types MUST have ID getters and setters for now\n    // bit annoying, but Im not sure yet how to get around this\n    pub fn setID(self: *Self, id: usize) void {\n        switch (self.*) {\n            .cat => |*cat| cat.id = id,\n            .dog => |*dog| dog.id = id,\n        }\n    }\n    pub fn getID(self: Self) usize {\n        switch (self) {\n            .cat => |cat| return cat.id,\n            .dog => |dog| return dog.id,\n        }\n    }\n\n    pub fn free(self: Self, allocator: Allocator) void {\n        switch (self) {\n            .cat => |cat| cat.free(allocator),\n            .dog => |dog| dog.free(allocator),\n        }\n    }\n};\n```\n\n## Save data to a Union datastor\n\n```zig\npub fn createTable() !void {\n    const gpa = std.heap.page_allocator;\n    var animalDB = try datastor.Table(Animal).init(gpa, \"db/animals.db\");\n    defer animalDB.deinit();\n\n    // add a cat\n    try animalDB.append(Animal{\n        .cat = .{\n            // NOTE - we dupe these items onto the heap, because we want these strings \n            // to live beyond the scope of just this function\n            .breed = try gpa.dupe(u8, \"Siamese\"),\n            .color = try gpa.dupe(u8, \"Sliver\"),\n            .length = 28,\n            .aggression = 0.9,\n        },\n    });\n\n    // add a dog\n    try animalDB.append(Animal{\n        .dog = .{\n            .breed = try gpa.dupe(u8, \"Colley\"),\n            .color = try gpa.dupe(u8, \"Black and White\"),\n            .height = 33,\n            .appetite = 0.9,\n        },\n    });\n\n    try animalDB.save();\n}\n\n```\n\n## Load Union data from a datastor\n\n```zig\npub fn loadTable() !void {\n    const gpa = std.heap.page_allocator;\n    var animalDB = try datastor.Table(Animal).init(gpa, \"db/animals.db\");\n    defer animalDB.deinit();\n\n    try animalDB.load();\n    for (animalDB.items(), 0..) |animal, i| {\n        std.debug.print(\"Animal {d} is {any}:\\n\", .{ i, animal });\n    }\n}\n```\n\nproduces output\n\n```zig\nAnimal 0 is animals.Animal{ .cat = ID: 1 Breed: Siamese Color: Sliver Length: 28, Aggression Factor: 9.00e-01 }:\nAnimal 1 is animals.Animal{ .dog = ID: 2 Breed: Colley Color: Black and White Height: 33, Appetite: 9.00e-01 }:\n```\n\n---\n\n# Tree / Heirachical Data examples\n\n## Define a complicated struct that also represents Tree structured data\n\n```zig\n////////////////////////////////////////////////////////////////////////////////\n// 3 types of things we can find in the forrest\n\nconst Tree = struct {\n    id: usize = 0,\n    parent_id: usize,\n    x: u8, y: u8, height: u8,\n};\n\nconst Creature = struct {\n    const Self = @This();\n    id: usize = 0,\n    parent_id: usize,\n    x: u8, y: u8, name: []const u8, weight: u8,\n\n    // needs a free() function because it has a slice that gets allocated\n    pub fn free(self: Self, allocator: Allocator) void {\n        allocator.free(self.name);\n    }\n};\n\nconst Rock = struct {\n    id: usize = 0,\n    parent_id: usize,\n    x: u8, y: u8, width: u8,\n};\n\nconst ForrestInhabitantType = enum { tree, creature, rock };\n\nconst Forrest = union(ForrestInhabitantType) {\n    const Self = @This();\n    tree: Tree,\n    creature: Creature,\n    rock: Rock,\n\n    // need these boilerplate functions to be able to act as datastor over this union type\n    pub fn setID(self: *Self, id: usize) void {\n        switch (self.*) {\n            .tree => |*tree| tree.id = id,\n            .creature => |*creature| creature.id = id,\n            .rock => |*rock| rock.id = id,\n        }\n    }\n\n    pub fn getID(self: Self) usize {\n        switch (self) {\n            .tree => |tree| return tree.id,\n            .creature => |creature| return creature.id,\n            .rock => |rock| return rock.id,\n        }\n    }\n\n    pub fn free(self: Self, allocator: Allocator) void {\n        switch (self) {\n            .creature => |creature| creature.free(allocator),\n            // only creatures need to be freed\n            else => {},\n        }\n    }\n\n    // adding these functions allows our forrest to act as a heirachy of nodes\n    pub fn setParentID(self: *Self, id: usize) void {\n        switch (self.*) {\n            .tree => |*tree| tree.parent_id = id,\n            .creature => |*creature| creature.parent_id = id,\n            .rock => |*rock| rock.parent_id = id,\n        }\n    }\n\n    pub fn getParentID(self: Self) usize {\n        switch (self) {\n            .tree => |tree| return tree.parent_id,\n            .creature => |creature| return creature.parent_id,\n            .rock => |rock| return rock.parent_id,\n        }\n    }\n};\n\n\n```\n\n## Add some data to the Forrest Datastor\n\n```zig\npub fn createTable() !void {\n    const gpa = std.heap.page_allocator;\n\n    var forrestDB = try datastor.Table(Forrest).init(gpa, \"db/forrest.db\");\n    defer forrestDB.deinit();\n\n    const root_id = try forrestDB.append(.{ .tree = .{ .parent_id = 0, .x = 10, .y = 10, .height = 10 } });\n    {\n        const pine_tree = try forrestDB.append(.{ .tree = .{ .parent_id = root_id, .x = 15, .y = 12, .height = 8 } });\n        {\n            _ = try forrestDB.append(.{ .creature = .{\n                .parent_id = pine_tree,\n                .x = 15,\n                .y = 12,\n                .name = try gpa.dupe(u8, \"Squirrel\"),\n                .weight = 3,\n            } });\n            _ = try forrestDB.append(.{ .rock = .{ .parent_id = pine_tree, .x = 15, .y = 12, .width = 2 } });\n        }\n        const gum_tree = try forrestDB.append(.{ .tree = .{ .parent_id = root_id, .x = 8, .y = 12, .height = 6 } });\n        {\n            _ = try forrestDB.append(.{ .creature = .{\n                .parent_id = gum_tree,\n                .x = 8,\n                .y = 12,\n                .name = try gpa.dupe(u8, \"Koala\"),\n                .weight = 10,\n            } });\n            _ = try forrestDB.append(.{ .creature = .{\n                .parent_id = gum_tree,\n                .x = 8,\n                .y = 12,\n                .name = try gpa.dupe(u8, \"Kangaroo\"),\n                .weight = 20,\n            } });\n        }\n        const weed = try forrestDB.append(.{ .tree = .{ .parent_id = root_id, .x = 5, .y = 5, .height = 2 } });\n        {\n            const moss_rock = try forrestDB.append(.{ .rock = .{ .parent_id = weed, .x = 5, .y = 6, .width = 2 } });\n            {\n                _ = try forrestDB.append(.{ .creature = .{\n                    .parent_id = moss_rock,\n                    .x = 5,\n                    .y = 6,\n                    .name = try gpa.dupe(u8, \"Ant\"),\n                    .weight = 1,\n                } });\n                _ = try forrestDB.append(.{ .creature = .{\n                    .parent_id = moss_rock,\n                    .x = 5,\n                    .y = 6,\n                    .name = try gpa.dupe(u8, \"Wasp\"),\n                    .weight = 1,\n                } });\n            }\n        }\n    }\n\n    try forrestDB.save();\n}\n```\n\n## Load and display Tree structured data using recursion\n\n```zig\n\nconst ForrestDB = datastor.Table(Forrest);\n\npub fn loadTable() !void {\n    const gpa = std.heap.page_allocator;\n    var forrestDB = try ForrestDB.init(gpa, \"db/forrest.db\");\n    defer forrestDB.deinit();\n\n    try forrestDB.load();\n\n    std.debug.print(\"Structured display for the contents of the forrest:\\n\\n\", .{});\n    try printForrestRecursive(forrestDB, 0, 0);\n}\n\nfn printForrestRecursive(forrestDB: ForrestDB, parent_id: usize, nesting: usize) !void {\n    const children = try forrestDB.getChildren(parent_id);\n    defer children.deinit();\n    for (children.items) |forrest| {\n        for (0..nesting) |_| {\n            std.debug.print(\"    \", .{});\n        }\n        std.debug.print(\" {}:\\n\", .{forrest});\n        try printForrestRecursive(forrestDB, forrest.getID(), nesting + 1);\n    }\n}\n\n```\n\nproduces output :\n\n```zig\nStructured display for the contents of the forrest:\n\n forrest.Forrest{ .tree = forrest.Tree{ .id = 1, .parent_id = 0, .x = 10, .y = 10, .height = 10 } }:\n     forrest.Forrest{ .tree = forrest.Tree{ .id = 2, .parent_id = 1, .x = 15, .y = 12, .height = 8 } }:\n         forrest.Forrest{ .creature = .id = 3, .parent_id = 2, .x = 15, .y = 12, .name = Squirrel, .weight = 3 }:\n         forrest.Forrest{ .rock = forrest.Rock{ .id = 4, .parent_id = 2, .x = 15, .y = 12, .width = 2 } }:\n     forrest.Forrest{ .tree = forrest.Tree{ .id = 5, .parent_id = 1, .x = 8, .y = 12, .height = 6 } }:\n         forrest.Forrest{ .creature = .id = 6, .parent_id = 5, .x = 8, .y = 12, .name = Koala, .weight = 10 }:\n         forrest.Forrest{ .creature = .id = 7, .parent_id = 5, .x = 8, .y = 12, .name = Kangaroo, .weight = 20 }:\n     forrest.Forrest{ .tree = forrest.Tree{ .id = 8, .parent_id = 1, .x = 5, .y = 5, .height = 2 } }:\n         forrest.Forrest{ .rock = forrest.Rock{ .id = 9, .parent_id = 8, .x = 5, .y = 6, .width = 2 } }:\n             forrest.Forrest{ .creature = .id = 10, .parent_id = 9, .x = 5, .y = 6, .name = Ant, .weight = 1 }:\n             forrest.Forrest{ .creature = .id = 11, .parent_id = 9, .x = 5, .y = 6, .name = Wasp, .weight = 1 }:\n```\n\nPlease note that in this example of loading and displaying a Heirachy, there is no thrashing of the Datastor \nto look up sub-queries of sub-queries from disk.\n\nThere is a single Disk I/O operation up front to load the entire Tree into memory, and then all the subsequent\ncalls to get the children of a node are just run against the in-memory tree.\n\nThis is fine (and super fast) for Tree data that remains relatively static.\n\n---\n\n# Performance\n\nerr ... Im not going to post benchmarks with the tiny amount of data I have here, no point.\nKeep in mind that disk IO occurs once at startup to load the data, and once every time a new event is added.\n\nAll data lookups are from memory only, so expect them to be quick. \n\nStatic data is indexed through the hashMap key, and timeseries event data is not indexed at all, just appended always in timestamp order. Therefore all event lookups are full table scans.\n\nThis should be fine for timeseries data up to ... 10k records before it starts melting down  ? (dont know, just guessing)\n\nAnything under 1000 records though, a full list scan is probably about as fast as a hashMap lookup anyway. (dont know, havnt measured yet)\n\nFor the record though ....\n\nOn a Mac M2 Pro, to create the Cats database, and timeseries events, insert all the records above, and save the data to disk = approx 1.5ms\n\nOnce the DB is created, running all the above queries, to:\n- generate a list of all events for all cats\n- generate a report of for each cat, show full audit trail\n- step through 4 different timestamps, and print the status of each cat at that point in time\n- then for all cats, show the current status based on  the last event\n\ntotal query time for all that = approx 30us (microseconds)  or 0.03ms\n\n----\n\n## TODO List / Future Goals \n\n- Be able to change the type of the ID field from `usize` to - anything.\n- Add automatic UUID stamps for all entities\n- Add the ability to pass functions so you can do `map/filter/reduce` type ops on the Datastor contents\n- Add something like a `datastor.zig.zon` file in a directory to allow some logical grouping of datastors into a larger DB schema\n- Data version management & migration updates \n- Be able to load and save objects in S2S binary format to HTTP endpoints / S3 style cloud storage \n- Add the ability to attach Middleware to datastors.  Idea is something like - register a callback to fire when a table is updated or a new event is added.\n- Add the ability to register clients that subscribe to event updates for a given record - needs that middleware function above.\n- Add the abliity to register user defined serializers on a per-user-struct basis (ie - if `serialize()` exists on the struct, then use it)\n- Ability to shard datastors that may get very large\n- Import / Export to and from Excel / CSV / JSON formats\n- Add multiple nodes, with replication and failover\n- Add option to use protobuf format as the serialization format\n\n## Future Goals - UI support\n\nThis comes in 2 parts.\n\nPart 1 is having these as library functions that you can add to your app that does :\n\n- Add a web based Datastor viewer (Zig app that spawns a local web server + HTMX app to navigate through stores, render datastor contents, etc)\n- Add a  Native UI app (Zig app using libui-ng tables)\n\nPart 2 is having a generic standalone program that does the same thing with existing datastor files.\n\nPart 1 is easy, because your app code already has the structs defined in code. Part 2 is going to be hard, as S2S provides no schema info.\nWill have to sort that problem out first\n\n",
  "owner_avatar_url": "https://avatars.githubusercontent.com/u/72305366?u=cf46defe1dc7db6770201913a79150fbcbddb6ff&v=4",
  "releases": [],
  "owner_bio": "Half Stack Dev.\r\n\r\nIâ€™m into minimalist code and tools.\r\n\r\n\r\n",
  "owner_company": null,
  "owner_location": "Outback Australia, middle of nowhere",
  "owner_blog": null,
  "owner_twitter_username": null,
  "owner_followers": 60,
  "owner_following": 59,
  "owner_created_at": "2020-10-03T12:46:34Z",
  "license": "MIT",
  "category": "library"
}