{
  "name": "log.zig",
  "owner": "karlseguin",
  "repo": "log.zig",
  "description": "A structured logger for Zig",
  "type": "package",
  "topics": [
    "logging-library",
    "structured-logging",
    "zig",
    "zig-library",
    "zig-package"
  ],
  "stars": 154,
  "forks": 9,
  "watchers": 2,
  "updated_at": "2025-12-06T21:17:19Z",
  "dependencies": [
    {
      "name": "metrics",
      "url": "https://github.com/karlseguin/metrics.zig/archive/13d8706e1ae921a8cc0d2f88283c1b5412c73e2f.tar.gz",
      "hash": "metrics-0.0.0-W7G4eP2_AQBKsaql3dhLJ-pkf-RdP-zV3vflJy4N34jC"
    }
  ],
  "readme": "Structured Logging for Zig\n\nlogz is an opinionated structured logger that outputs to stdout, stderr, a file or a custom writer using logfmt or JSON. It aims to minimize runtime memory allocation by using a pool of pre-allocated loggers. \n\n# Metrics\nIf you're looking for metrics, check out my <a href=\"https://github.com/karlseguin/metrics.zig\">prometheus library for Zig</a>.\n\n# Installation\nThis library supports native Zig module (introduced in 0.11). Add a \"logz\" dependency to your `build.zig.zon`.\n\n## Zig 0.11\nPlease use the [zig-0.11](https://github.com/karlseguin/log.zig/tree/zig-0.11) branch for a version of the library which is compatible with Zig 0.11.\n\nThe master branch of this library follows Zig's master.\n\n# Usage\nFor simple cases, a global logging pool can be configured and used:\n\n```zig\n// initialize a logging pool\ntry logz.setup(allocator, .{\n    .level = .Info, \n    .pool_size = 100,\n    .buffer_size = 4096, \n    .large_buffer_count = 8,\n    .large_buffer_size = 16384,\n    .output = .stdout,\n    .encoding = .logfmt,\n});\ndefer logz.deinit();\n\n// other places in your code\nlogz.info().string(\"path\", req.url.path).int(\"ms\", elapsed).log();\n\n// The src(@src()) + err(err) combo is great for errors\nlogz.err().src(@src()).err(err).log();\n```\n\nAlternatively, 1 or more explicit pools can be created:\n\n```zig\nvar requestLogs = try logz.Pool.init(allocator, .{});\ndefer requestLogs.deinit();\n\n// requestLogs can be shared across threads\nrequestLogs.err().\n    string(\"context\", \"divide\").\n    float(\"a\", a).\n    float(\"b\", b).log();\n```\n\n`logz.Level.parse([]const u8) ?Level` can be used to convert a string into a logz.Level.\n\nThe configuration `output` can be `.stdout`, `.stderr` or a `.{.file = \"PATH TO FILE}`. More advanced cases can use `logTo(writer: anytype)` instead of `log()`.\n\nThe configuration `encoding` can be either `logfmt` or `json`.\n\n# Important Notes\n1. Attribute keys are never escaped. logz assumes that attribute keys can be written as is.\n2. Logz can silently drop attributes from a log entry. This only happens when the attribute exceeds the configured sized (either of the buffer or the buffer + large_buffer) or a large buffer couldn't be created.\n3. Depending on the `pool_strategy` configuration, when empty the pool will either dynamically create a logger (`.pool_strategy = .create`) or return a noop logger (`.pool_strategy = .noop)`. If creation fails, a noop logger will be return and an error is written using `std.log.err`.\n\n## Pools and Loggers\nPools are thread-safe.\n\nThe following functions returns a logger:\n\n* `pool.debug()`\n* `pool.info()`\n* `pool.warn()`\n* `pool.err()`\n* `pool.fatal()`\n* `pool.logger()`\n* `pool.loggerL()`\n\nThe returned logger is NOT thread safe. \n\n### Attributes\nThe logger can log:\n* `fmt(key: []const u8, comptime format: []const u8, values: anytype)`\n* `string(key: []const u8, value: ?[]const u8)`\n* `stringZ(key: []const u8, value: ?[*:0]const u8)`\n* `boolean(key: []const u8, value: ?boolean)`\n* `int(key: []const u8, value: ?any_int)`\n* `float(key: []const u8, value: ?any_float)`\n* `binary(key: []const u8, value: ?[]const u8)` - will be url_base_64 encoded\n* `err(e: anyerror)` - same as `errK(\"@err\", e)`;\n* `errK(key: []const u8, e: anyerror)`\n* `stringSafe(key: []const u8, value: ?[]const u8)` - assumes value doesn't need to be encoded\n* `stringSafeZ(key: []const u8, value: ?[*:0]const u8)` - assumes value doesn't need to be encoded\n* `ctx(value: []const u8)` - same as `stringSafe(\"@ctx\", value)`\n* `src(value: std.builtin.SourceLocation)` - Logs an `std.builtin.SourceLocation`, the type of value you get from the `@src()` builtin.\n\n### Log Level\nPools are configured with a minimum log level:\n\n* `logz.Level.Debug`\n* `logz.Level.Info`\n* `logz.Level.Warn`\n* `logz.Level.Error`\n* `logz.Level.Fatal`\n* `logz.Level.None`\n\nWhen getting a logger for a value lower than the configured level, a noop logger is returned. This logger exposes the same API, but does nothing.\n\n```zig\nvar logs = try logz.Pool.init(allocator, .{.level = .Error});\n\n// this won't do anything\nlogs.info().bool(\"noop\", true).log();\n```\n\nThe noop logger is meant to be relatively fast. But it doesn't eliminate any complicated values you might pass. Consider this example:\n\n```zig\nvar logs = try logz.Pool.init(allocator, .{.level = .None});\ntry logs.warn().\n    string(\"expensive\", expensiveCall()).\n    log();\n```\n\nAlthough the logger is disabled (the log level is `Fatal`), the `expensiveCall()` function is still called. In such cases, it's necessary to use the `pool.shouldLog` function:\n\n```zig\nif (pool.shouldLog(.Warn)) {\n    try logs.warn().\n        string(\"expensive\", expensiveCall()).\n        log();\n}\n```\n\n### Config\nPools use the following configuration. The default value for each setting is show:\n\n```zig\npub const Config = struct {\n    // The number of loggers to pre-allocate. \n    pool_size: usize = 32,\n\n    // Controls what the pool does when empty. It can either dynamically create\n    // a new Logger, or return the Noop logger.\n    pool_startegy: .create, // or .noop\n\n    // Each logger in the pool is configured with a static buffer of this size.\n    // An entry that exceeds this size will attempt to expand into the \n    // large buffer pool. Failing this, attributes will be dropped\n    buffer_size: usize = 4096,\n\n    // The minimum log level to log. `.None` disables all logging\n    level: logz.Level = .Info,\n\n    // Data to prepend at the start of every logged message from this pool\n    // See the Advanced Usage section\n    prefix: ?[]const u8 = null,\n\n    // Where to write the output: can be either .stdout or .stderr\n    output: Output = .stdout, // or .stderr, or .{.file = \"PATH TO FILE\"}\n\n    encoding: Encoding = .logfmt, // or .json\n\n    // How many large buffers to create\n    large_buffer_count: u16 = 8,\n\n    // Size of large buffers.\n    large_buffer_size: usize = 16384,\n\n    // Controls what the large buffer pool does when empty. It can either \n    // dynamically create a large buffer, or drop the attribute\n    large_buffer_startegy: .create, // or .drop\n};\n```\n\n### Timestamp and Level\nWhen using the `debug`, `info`, `warn`, `err` or `fatal` functions, logs will always begin with `@ts=$MILLISECONDS_SINCE_JAN1_1970_UTC @l=$LEVEL`, such as: `@ts=1679473882025 @l=INFO`. With JSON encoding, the object will always have the `\"@ts\"` and `\"@l\"` fields.\n\n### Logger Life cycle\nThe logger is implicitly returned to the pool when `log`, `logTo` or `tryLog` is called. In rare cases where `log`, `logTo` or `tryLog` are not called, the logger must be explicitly released using its `release()` function:\n\n```zig\n// This is a contrived example to show explicit release\nvar l = logz.info();\n_  = l.string(\"key\", \"value\");\n\n// actually, on second thought, I don't want to log anything\nl.release();\n```\n\n### Method Chaining\nLoggers are mutable. The method chaining (aka fluent interface) is purely cosmetic. The following are equivalent:\n\n```zig\n// chaining\ninfo().int(\"over\", 9000).log();\n\n// no chaining\nvar l = info();\n_ = l.int(\"over\", 9000);\nl.log();\n```\n\n### tryLog\nThe call to `log` can fail. On failure, a message is written using `std.log.err`. However, `log` returns `void` to improve the API's usability (it doesn't require callers to `try` or `catch`).\n\n`tryLog` can be used instead of `log`. This function returns a `!void` and will not write to `std.log.err` on failure.\n\n## Advanced Usage\n\n### Pre-setup\n`setup(CONFIG)` can be called multiple times, but isn't thread safe. The idea is that, at the very start, `setup` can be called with a minimal config so that any startup errors can be logged. After startup, but before the full application begins, `setup` is called a 2nd time with the correct config. Something like:\n\n```zig\npub fn main() !void {\n    var general_purpose_allocator = std.heap.GeneralPurposeAllocator(.{}){};\n    const allocator = general_purpose_allocator.allocator();\n\n    // minimal config so that we can use logz will setting things up\n    try logz.setup(.{\n        .pool_size = 2, \n        .max_size = 4096, \n        .level = .Warn\n    });\n\n    // can safely call logz functions, since we now have a mimimal setup\n    const config = loadConfig();\n    // more startup things here\n\n    // ok, now setup our full logger (which we couldn't do until we read \n    // our config, which could have failed)\n\n    try logz.setup(.{\n        .pool_size = config.log.pool_size, \n        .max_size = config.log.max_size,\n        .level = config.log.level\n    });\n    ...\n}\n```\n\n### Prefixes\nA pool can be configured with a prefix by setting the `prefix` field of the configuration. When set, all log entries generated by loggers of this pool will contain the prefix. \n\nThe prefix is written as-is.\n\n```zig\n// prefix can be anything []const u8. It doesn't have to be a key=value\n// it will not be encoded if needed, and doesn't even have to be a valid string.\nvar p = try logz.Pool.init(allocator, .{.prefix = \"keemun\"});\ndefer p.deinit();\n\np.info().boolean(\"tea\", true).log();\n```\n\nThe above will generate a log line: `keemun @ts=TIMESTAMP @l=INFO tea=Y\"`\n\nWhen using `.json` encoding, your prefix must begin the object:\n\n```zig:\nvar p = try logz.Pool.init(allocator, .{.prefix = \"=={\"});\ndefer p.deinit();\n\np.info().boolean(\"tea\", true).log();\n```\nThe above will generate a log line: `=={\"@ts\":TIMESTAMP, \"@l\":\"INFO\", \"tea\":true}`\n\n### Multi-Use Logger\nRather than having a logger automatically returned to the pool when `.log()` or `tryLog()` are called, it is possible to flag the logger for \"multi-use\". In such cases, the logger must be explicitly returned to the pool using `logger.release()`. This can be enabled by calling `multiuse` on the logger. Logs created by the logger will share the same attributes up to the point where multiuse was called:\n\n```zig\nvar logger = logz.logger().string(\"request_id\", request_id).multiuse();\ndefer logger.release(); // important\n\nlogger.int(\"status\", status_code).int(\"ms\", elapsed_time).level(.Info).log()\n...\nlogger.err(err).string(\"details\", \"write failed\").level(.Error).log()\n```\n\nThe above logs 2 distinct entries, both of which will contain the \"request_id=XYZ\" attribute. Do remember that while the logz.Pool is thread-safe, individual loggers are not. A multi-use logger should not be used across threads.\n\n### Deferred Level\nThe `logger()` function returns a logger with no level. This can be used to defer the level:\n\n```zig\nvar logger = logz.logger().\n    stringSafe(\"ctx\", \"db.setup\").\n    string(\"path\", path);\ndefer logger.log();\n\nconst db = zqlite.open(path, true) catch |err| {\n    _ = logger.err(err).level(.Fatal);\n}\n\n_ = logger.level(.Info);\nreturn db;\n```\n\nPreviously, we saw how an internal \"noop\" logger is returned when the log level is less than the configured log level. With a log level of `Warn`, the following is largely 3 noop function calls:\n\n```zig\nlog.info().string(\"path\", path).log();\n```\n\nWith deferred log levels, this isn't possible - the configured log level is only considered when `log` (or `tryLog`) is called. Again, given a log level of `Warn`, the following **will not** log anything, but the call to `string(\"path\", path)` is not a \"noop\":\n\n```zig\nvar l = log.logger().string(\"path\", path);\n_ = l.level(.Info);\nl.log(); \n```\n\nThe `log.loggerL(LEVEL)` function is a very minor variant which allows setting a default log level. Using it, the original deferred example can be rewritten:\n\n```zig\nvar logger = logz.loggerL(.Info).\n    stringSafe(\"ctx\", \"db.setup\").\n    string(\"path\", path);\ndefer logger.log();\n\nconst db = zqlite.open(path, true) catch |err| {\n    _ = logger.err(err).level(.Fatal);\n}\n\n// This line is removed\n// logger.level(.Info);\nreturn db;\n```\n\n`errdefer` can be used with deferred logging as a simple and generic way to log errors. The above can be re-written as:\n\n```zig\nvar logger = logz.loggerL(.Info).\n    stringSafe(\"ctx\", \"db.setup\").\n    string(\"path\", path);\ndefer logger.log();\nerrdefer |err| _ = logger.err(err).level(.Fatal);\n\nreturn zqlite.open(path, true);\n```\n\n### Allocations\nWhen configured with `.pool_strategy = .noop` and `.large_buffer_strategy = .drop`, the logger will not allocate memory after the pool is initialized.\n\n### Maximum Log Line Size\nThe maximum possible log entry is: `config.prefix.len + config.buffer_size + config.large_buffer_size + ~35`.  \n\nTh last 35 bytes is for the the @ts and @l attributes, and the trailing newline. The exact length of these can vary by a few bytes (e.g. the json encoder takes a few additional bytes to quote the key).\n\n### Custom Output\nThe `logTo(writer: anytype)` can be called instead of `log()`. The writer must expose 1 method:\n\n* `writeAll(self: Self, data: []const u8) !void`\n\nA single call to `logTo()` can result in multiple calls to `writeAll`. `logTo` uses a mutex to ensure that a single entry is written to the writer at a time.\n\n## Testing\nWhen testing, I recommend you do the following in your main test entry:\n\n```zig\nvar leaking_gpa = std.heap.GeneralPurposeAllocator(.{}){};\nconst leaking_allocator = leaking_gpa.allocator();\n\ntest {\n    try logz.setup(leaking_allocator, .{.pool_size = 5, .level = .None});\n\n    // rest of your setup, such as::\n    std.testing.refAllDecls(@This());\n}\n```\n\nFirst, you should not use `std.testing.allocator` since Zig offers no way to cleanup globals after tests are run. In the above, the `logz.Pool` *will* leak (but that should be ok in a test).\n\nSecond, notice that we're using a global allocator. This is because the pool may need to dynamically allocate a logger, and thus the allocator must exist for the lifetime of the pool. Strictly speaking, this can be avoided if you know that the pool will never need to allocate a dynamic logger, so setting a sufficiently large `pool_size` would also work.\n\nFinally, you should set the log level to '.None' until the following Zig  issue is fixed [https://github.com/ziglang/zig/issues/15091](https://github.com/ziglang/zig/issues/15091).\n\n## Metrics\nA few basic metrics are collected using [metrics.zig](https://github.com/karlseguin/metrics.zig), a prometheus-compatible library. These can be written to an `std.io.Writer` using `try logz.writeMetrics(writer)`. As an example using [httpz](https://github.com/karlseguin/http.zig):\n\n```zig\npub fn metrics(_: *httpz.Request, res: *httpz.Response) !void {\n    const writer = res.writer();\n    try logz.writeMetrics(writer);\n\n    // also write out the httpz metrics\n    try httpz.writeMetrics(writer);\n}\n```\n\nThe metrics are:\n\n* `logz_no_space` - counts the number of bytes which resulted in an attribute being dropped from a log. Consider increasing `buffer_size` and/or `large_buffer_size`.\n* `logz_pool_empty` - counts the number of times the log pool was empty. Depending on the `pool_startegy` configuration, this either results in a logger being dynamically allocated, or a log message being dropped. Consider increasing `pool_size`.\n* `logz_large_buffer_empty` - counts the number of times the large buffer pool was empty. Depending on the `large_buffer_startegy` configuration, this either in a large buffer being dynamically allocated, or part of a log being dropped. Consider increasing `large_buffer_count`.\n* `logz_large_buffer_acquire` - counts the number of times a large buffer was successfully retrived from the large buffer pool. This is not particularly problematic, but, as the large buffer pool is a limited and mutex-protected, this can be reduced by increasing `buffer_size`.\n",
  "owner_avatar_url": "https://avatars.githubusercontent.com/u/206480?v=4",
  "releases": [],
  "owner_company": null,
  "owner_location": null,
  "owner_blog": "https://www.openmymind.net/",
  "owner_twitter_username": "karlseguin",
  "owner_followers": 2253,
  "owner_following": 3,
  "owner_created_at": "2010-02-19T04:01:58Z",
  "license": "MIT",
  "category": "library"
}