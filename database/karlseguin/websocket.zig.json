{
  "name": "websocket.zig",
  "owner": "karlseguin",
  "repo": "websocket.zig",
  "description": "A websocket implementation for zig",
  "type": "project",
  "topics": [
    "websocket",
    "zig",
    "zig-package",
    "zig-library"
  ],
  "stars": 454,
  "forks": 61,
  "watchers": 6,
  "updated_at": "2025-12-04T09:22:55Z",
  "readme": "# A zig websocket server.\nThe master branch targets the latest stable of Zig (0.15.1). The dev branch targets the latest version of Zig. If you're looking for an older version, look for an zig-X.YZ branches.\n\nSkip to the [client section](#client).\n\nIf you're upgrading from a previous version, check out the [Server Migration](https://github.com/karlseguin/websocket.zig/wiki/Server-Migration) and [Client Migration](https://github.com/karlseguin/websocket.zig/wiki/Client-Migration) wikis.\n\n# Server\n```zig\nconst std = @import(\"std\");\nconst ws = @import(\"websocket\");\n\npub fn main() !void {\n    var gpa = std.heap.GeneralPurposeAllocator(.{}){};\n    const allocator = gpa.allocator();\n\n    var server = try ws.Server(Handler).init(allocator, .{\n        .port = 9224,\n        .address = \"127.0.0.1\",\n        .handshake = .{\n            .timeout = 3,\n            .max_size = 1024,\n            // since we aren't using hanshake.headers\n            // we can set this to 0 to save a few bytes.\n            .max_headers = 0,\n        },\n    });\n\n    // Arbitrary (application-specific) data to pass into each handler\n    // Pass void ({}) into listen if you have none\n    var app = App{};\n\n    // this blocks\n    try server.listen(&app);\n}\n\n// This is your application-specific wrapper around a websocket connection\nconst Handler = struct {\n    app: *App,\n    conn: *ws.Conn,\n\n    // You must define a public init function which takes\n    pub fn init(h: *ws.Handshake, conn: *ws.Conn, app: *App) !Handler {\n        // `h` contains the initial websocket \"handshake\" request\n        // It can be used to apply application-specific logic to verify / allow\n        // the connection (e.g. valid url, query string parameters, or headers)\n\n        _ = h; // we're not using this in our simple case\n\n        return .{\n            .app = app,\n            .conn = conn,\n        };\n    }\n\n    // You must defined a public clientMessage method\n    pub fn clientMessage(self: *Handler, data: []const u8) !void {\n        try self.conn.write(data); // echo the message back\n    }\n};\n\n// This is application-specific you want passed into your Handler's\n// init function.\nconst App = struct {\n  // maybe a db pool\n  // maybe a list of rooms\n};\n```\n\n## Handler\nWhen you create a `websocket.Server(Handler)`, the specified `Handler` is your structure which will receive messages. It must have a public `init` function and `clientMessage` method. Other methods, such as `close` can optionally be defined.\n\n### init\nThe `init` method is called with a `*websocket.Handshake`, a `*websocket.Conn` and whatever app-specific value was passed into `Server(H).init`. \n\nWhen `init` is called, the handshake response has not yet been sent to the client (this allows your `init` method to return an error which will cause websocket.zig to send an error response and close the connection). As such, you should not use/write to the `*websocket.Conn` at this point. Instead, use the `afterInit` method, described next.\n\nThe websocket specification requires the initial \"handshake\" to contain certain headers and values. The library validates these headers. However applications may have additional requirements before allowing the connection to be \"upgraded\" to a websocket connection. For example, a one-time-use token could be required in the querystring. Applications should use the provided `websocket.Handshake` to apply any application-specific verification and optionally return an error to terminate the connection.\n\nThe `*websocket.Handshake` exposes the following fields:\n\n* `url: []const u8` - URL of the request in its original casing\n* `method: []const u8` - Method of the request in its original casing\n* `raw_headers: []const u8` - The raw \"key1: value1\\r\\nkey2: value2\\r\\n\" headers. Keys are lowercase.\n\nIf you set the `max_headers` configuration value to > 0, then you can use `req.headers.get(\"HEADER_NAME\")` to extract a header value from the given name:\n\nIf you set the `max_res_headers` configuration value to > 0, then you can set headers to be sent in the handshake response:\n\n```zig\npub fn init(h: *ws.Handshake, conn: *ws.Conn, app: *App) !Handler {\n    h.res_headers.add(\"set-cookie\", \"delicious\")\n    //...\n}\n```\n\nNote that, currently, the total length of the headers added to `res_headers` should not exceed 1024 characters, else you will exeperience an out of bounds segfault.\n\n```zig\n// the last parameter, an *App in this case, is an application-specific\n// value that you passed into server.listen()\npub fn init(h: *websocket.Handshake, conn: websocket.Conn, app: *App) !Handler {\n    // get returns a ?[]const u8\n    // the name is lowercase\n    // the value is in its original case\n    const token = handshake.headers.get(\"authorization\") orelse {\n        return error.NotAuthorized;\n    }\n\n    return .{\n        .app = app,\n        .conn = conn,\n    };\n}\n\n```\n\nYou can iterate through all the headers:\n```zig\nvar it = handshake.headers.iterator();\nwhile (it.next) |kv| {\n    std.debug.print(\"{s} = {s}\\n\", .{kv.key, kv.value});\n}\n```\n\nMemory referenced by the `websocket.Handshake`, including headers from `handshake.headers` will be freed after the call to `init` completes. Application that need these values to exist beyond the call to `init` must make a copy.\n\n### afterInit\nIf your handler defines a `afterInit(handler: *Handler) !void` method, the method is called after the handshake response has been sent. This is the first time the connection can safely be used.\n\n`afterInit` supports two overloads:\n\n```zig\npub fn afterInit(handler: *Handler) !void\npub fn afterInit(handler: *Handler, ctx: anytype) !void\n```\n\nThe `ctx` is the same `ctx` passed into `init`. It is passed here for cases where the value is only needed once when the connection is established.\n\n### clientMessage\nThe `clientMessage` method is called whenever a text or binary message is received.\n\nThe `clientMessage` method can take one of four shapes. The simplest, shown in the first example, is:\n\n```zig\n// simple clientMessage\nclientMessage(h: *Handler, data: []u8) !void\n```\n\nThe Websocket specific has a distinct message type for text and binary. Text messages must be valid UTF-8. Websocket.zig does not do this validation (it's expensive and most apps don't care). However, if you do care about the distinction, your `clientMessage` can take another parameter:\n\n```zig\n// clientMessage that accepts a tpe to differentiate between messages\n// sent as `text` vs those sent as `binary`. Either way, Websocket.zig\n// does not validate that text data is valid UTF-8.\nclientMessage(h: *Handler, data: []u8, tpe: ws.MessageTextType) !void\n```\n\nFinally, `clientMessage` can take an optional `std.mem.Allocator`. If you need to dynamically allocate memory within `clientMessage`, consider using this allocator. It is a fast thread-local buffer that fallsback to an arena allocator. Allocations made with this allocator are freed after `clientMessage` returns:\n\n```zig\n// clientMessage that takes an allocator\nclientMessage(h: *Handler, allocator: Allocator, data: []u8) !void\n\n// cilentMessage that takes an allocator AND a MessageTextType\nclientMessage(h: *Handler, allocator: Allocator, data: []u8, tpe: ws.MessageTextType) !void`\n```\n\nIf `clientMessage` returns an error, the connection is closed. You can also call `conn.close()` within the method.\n\n### close\nIf your handler defines a `close(handler: *Handler)` method, the method is called whenever the connection is being closed. Guaranteed to be called exactly once, so it is safe to deinitialize the `handler` at this point. This is called no mater the reason for the closure (on shutdown, if the client closed the connection, if your code close the connection, ...)\n\nThe socket may or may not still be alive.\n\n### clientClose\nIf your handler defines a `clientClose(handler: *Handler, data: []u8) !void` method, the function will be called whenever a `close` message is received from the client. \n\nYou almost certainly *do not* want to define this method and instead want to use `close()`. When not defined, websocket.zig follows the websocket specific and replies with its own matching close message.\n\n### clientPong\nIf your handler defines a `clientPong(handler: *Handler, data: []u8) !void` method, the function will be called whenever a `pong` message is received from the client. When not defined, no action is taken.\n\n### clientPing\nIf your handler defines a `clientPing(handler: *Handler, data: []u8) !void` method, the function will be called whenever `ping` message is received from the client. When not defined, websocket.zig will write a corresponding `pong` reply.\n\n## websocket.Conn\nThe call to `init` includes a `*websocket.Conn`. It is expected that handlers will keep a reference to it. The main purpose of the `*Conn` is to write data via `conn.write([]const u8)` and `conn.writeBin([]const u8)`. The websocket protocol differentiates between a \"text\" and \"binary\" message, with the only difference that \"text\" must be valid UTF-8. This library does not enforce this. Which you use really depends on what your client expects. For browsers, text messages appear as strings, and binary messages appear as a Blob or ArrayBuffer (depending on how the client is configured).\n\n`conn.close(.{})` can also be called to close the connection. Calling `conn.close()` **will** result in the handler's `close` callback being called. \n\n`close` takes an optional value where you can specify the `code` and/or `reason`: `conn.close(.{.code = 4000, .reason = \"bye bye\"})` Refer to [RFC6455](https://datatracker.ietf.org/doc/html/rfc6455#section-7.4.1) for valid codes. The `reason` must be <= 123 bytes.\n\n### Writer\nIt's possible to get a `*std.Io.Writer` from a `*Conn`. Because websocket messages are framed, the writter will buffer the message in memory and requires an explicit \"send\". Buffering requires an allocator. \n\n```zig\n// .text or .binary\nvar wb = conn.writeBuffer(allocator, .text);\ndefer wb.deinit();\ntry wb.interface.print(\"it's over {d}!!!\", .{9000});\ntry wb.send();\n```\n\nConsider using the `clientMessage` overload which accepts an allocator. Not only is this allocator fast (it's a thread-local buffer than fallsback to an arena), but it also eliminates the need to call `deinit`:\n\n```zig\npub fn clientMessage(h: *Handler, allocator: Allocator, data: []const u8) !void {\n    // Use the provided allocator.\n    // It's faster and doesn't require `deinit` to be called\n\n    var wb = conn.writeBuffer(allocator, .text);\n    try std.fmt.format(wb.writer(), \"it's over {d}!!!\", .{9000});\n    try wb.send();\n}\n```\n\n## Thread Safety\nWebsocket.zig ensures that only 1 message per connection/handler is processed at a time. Therefore, you will never have concurrent calls to `clientMessage`, `clientPing`, `clientPong` or `clientClose`. Conversely, concurrent calls to methods of `*websocket.Conn` are allowed (i.e. `conn.write` and `conn.close`). \n\n## Config\nThe 2nd parameter to `Server(H).init` is a configuration object. \n\n```zig\npub const Config = struct {\n    port: u16 = 9882,\n\n    // Ignored if unix_path is set\n    address: []const u8 = \"127.0.0.1\",\n\n    // Not valid on windows\n    unix_path: ?[]const u8 = null,\n\n    // In nonblocking mode (Linux/Mac/BSD), sets the number of\n    // listening threads. Defaults to 1.\n    // In blocking mode, this is ignored and always set to 1.\n    worker_count: ?u8 = null,\n\n    // The maximum number of connections, per worker.\n    // default: 16_384\n    max_conn: ?usize = null,\n\n    // The maximium allows message size. \n    // A websocket message can have up to 14 bytes of overhead/header\n    // Default: 65_536\n    max_message_size: ?usize = null,\n\n    handshake: Config.Handshake = .{},\n    thread_pool: ThreadPool = .{},\n    buffers: Config.Buffers = .{},\n\n    // compression is disabled by default\n    compression: ?Compression = null,\n\n    // In blocking mode the thread pool isn't used \n    pub const ThreadPool = struct {\n        // Number of threads to process messages.\n        // These threads are where your `clientXYZ` method will execute.\n        // Default: 4.\n        count: ?u16 = null,\n\n        // The maximum number of pending requests that the thread pool will accept\n        // This applies back pressure to worker and ensures that, under load\n        // pending requests get precedence over processing new requests.\n        // Default: 500.\n        backlog: ?u32 = null,\n\n        // Size of the static buffer to give each thread. Memory usage will be \n        // `count * buffer_size`.\n        // If clientMessage isn't defined with an Allocator, this defaults to 0.\n        // Else it default to 32768\n        buffer_size: ?usize = null,\n    };\n\n    const Handshake = struct {\n        // time, in seconds, to timeout the initial handshake request\n        timeout: u32 = 10,\n\n        // Max size, in bytes, allowed for the initial handshake request.\n        // If you're expected a large handshake (many headers, large cookies, etc)\n        // you'll need to set this larger.\n        // Default: 1024\n        max_size: ?u16 = null,\n\n        // Max number of headers to capture. These become available as\n        // handshake.headers.get(...).\n        // Default: 0\n        max_headers: ?u16 = null,\n\n        // Count of handshake objects to keep in a pool. More are created\n        // as needed.\n        // Default: 32\n        count: ?u16 = null,\n    };\n\n    const Buffers = struct {\n        // The number of \"small\" buffers to keep pooled.\n        //\n        // When `null`, the small buffer pool is disabled and each connection\n        // gets its own dedicated small buffer (of `size`). This is reasonable\n        // when you expect most clients to be sending a steady stream of data.\n        \n        // When set > 0, a pool is created (of `size` buffers) and buffers are \n        // assigned as messages are received. This is reasonable when you expect\n        // sporadic and messages from clients.\n        //\n        // Default: `null`\n        small_pool: ?usize = null,\n\n        // The size of each \"small\" buffer. Depending on the value of `pool`\n        // this is either a per-connection buffer, or the size of pool buffers\n        // shared between all connections\n        // Default: 2048\n        small_size: ?usize = null,\n\n        // The number of large buffers to have in the pool.\n        // Messages larger than `buffers.small_size` but smaller than `max_message_size`\n        // will attempt to use a large buffer from the pool.\n        // If the pool is empty, a dynamic buffer is created.\n        // Default: 8\n        large_pool: ?u16 = null,\n\n        // The size of each large buffer.\n        // Default: min(2 * buffers.small_size, max_message_size)\n        large_size: ?usize = null,\n    };\n\n    // Compression is disabled by default, to enable it and accept the default\n    // values, set it to a defautl struct: .{}\n    const Compression = struct {\n        // The mimimum size of data before messages will be compressed\n        // null = message are never compressed when writing messages to the client\n        // If you want to enable compression, 512 is a reasonable default\n        write_threshold: ?usize = null,\n\n        // When compression is enable, and write_treshold != null, every connection\n        // gets an std.ArrayList(u8) to write the compressed message to. When this\n        // is true, the memory allocated to the ArrayList is kept for subsequent\n        // messages (i.e. it calls `clearRetainingCapacity`). When false, the memory\n        // is freed after each message. \n        // true = more memory, but fewer allocations\n        retain_write_buffer: bool = true,\n    };\n}\n```\n\n## Logging\nwebsocket.zig uses Zig's built-in scope logging. You can control the log level by having an `std_options` decleration in your program's main file:\n\n```zig\npub const std_options = std.Options{\n    .log_scope_levels = &[_]std.log.ScopeLevel{\n        .{ .scope = .websocket, .level = .err },\n    }\n};\n```\n\n## Advanced\n\n### Pre-Framed Comptime Message\nWebsocket message have their own special framing. When you use `conn.write` or `conn.writeBin` the data you provide is \"framed\" into a correct websocket message. Framing is fast and cheap (e.g., it DOES NOT require an O(N) loop through the data). Nonetheless, there may be be cases where pre-framing messages at compile-time is desired. The `websocket.frameText` and `websocket.frameBin` can be used for this purpose:\n\n```zig\nconst UNKNOWN_COMMAND = websocket.frameText(\"unknown command\");\n...\n\npub fn clientMessage(self: *Handler, data: []const u8) !void {\n    if (std.mem.startsWith(u8, data, \"join: \")) {\n        self.handleJoin(data)\n    } else if (std.mem.startsWith(u8, data, \"leave: \")) {\n        self.handleLead(data)\n    } else {\n        try self.conn.writeFramed(UNKNOWN_COMMAND);\n    }\n}\n```\n\n### Blocking Mode\nkqueue (BSD, MacOS) or epoll (Linux) are used on supported platforms. On all other platforms (most notably Windows), a more naive thread-per-connection with blocking sockets is used.\n\nThe comptime-safe, `websocket.blockingMode() bool` function can be called to determine which mode websocket is running in (when it returns `true`, then you're running the simpler blocking mode).\n\n### Per-Connection Buffers\nIn non-blocking mode, the `buffers.small_pool` and `buffers.small_size` should be set for your particular use case. When `buffers.small_pool == null`, each connection gets its own buffer of `buffers.small_size` bytes. This is a good option if you expect most of your clients to be sending a steady stream of data. While it might take more memory (# of connections * buffers.small_size), its faster and minimizes multi-threading overhead.\n\nHowever, if you expect clients to only send messages sporadically, such as a chat application, enabling the pool can reduce memory usage at the cost of a bit of overhead.\n\nIn blocking mode, these settings are ignored and each connection always gets its own buffer (though there is still a shared large buffer pool).\n\n### Stopping\n`server.stop()` can be called to stop the webserver. It is safe to call this from a different thread (i.e. a `sigaction` handler).\n\n## Testing\nThe library comes with some helpers for testing.\n\n```zig\nconst wt = @import(\"websocket\").testing;\n\ntest \"handler: echo\" {\n    var wtt = wt.init(.{});\n    defer wtt.deinit();\n\n    // create an instance of your handler (however you want)\n    // and use &tww.conn as the *ws.Conn field\n    var handler = Handler{\n        .conn = &wtt.conn,\n    };\n\n    // execute the methods of your handler\n    try handler.clientMessage(\"hello world\");\n\n    // assert what the client should have received\n    try wtt.expectMessage(.text, \"hello world\");\n}\n```\n\nBesides `expectMessage` you can also call `expectClose()`.\n\nNote that this testing is heavy-handed. It opens up a pair of sockets with one side listening on `127.0.0.1` and accepting a connection from the other. `wtt.conn` is the \"server\" side of the connection, and assertion happens on the client side.\n\n# Client\nThe `*websocket.Client` can be used in one of two ways. At its simplest, after creating a client and initiating a handshake, you simply use <code>write</code> to send messages and <code>read</code> to receive them. First, we create the client and initiate the handshake:\n\n```zig\npub fn main() !void {\n  var gpa = std.heap.GeneralPurposeAllocator(.{}){};\n  const allocator = gpa.allocator();\n\n  // create the client\n  var client = try websocket.Client.init(allocator, .{\n    .port = 9224,\n    .host = \"localhost\",\n  });\n  defer client.deinit();\n\n  // send the initial handshake request\n  const request_path = \"/ws\";\n  try client.handshake(request_path, .{\n    .timeout_ms = 1000,\n    // Raw headers to send, if any. \n    // A lot of servers require a Host header.\n    // Separate multiple headers using \\r\\n\n    .headers = \"Host: localhost:9224\",\n  });\n}\n```\n\nWe can then use `read` and `write`. By default, `read` blocks until a message is received (or an error occurs). We can make it return `null` by setting a timeout:\n\n```zig\n  // optional, read will return null after 1 second\n  try client.readTimeout(std.time.ms_per_s * 1);\n\n  // echo messages back to the server until the connection is closed\n  while (true) {\n    // since we didn't set a timeout, client.read() will either\n    // return a message or an error (i.e. it won't return null)\n    const message = (try client.read()) orelse {\n        // no message after our 1 second\n        std.debug.print(\".\", .{});\n        continue;\n    };\n\n    // must be called once you're done processing the request\n    defer client.done(message);\n\n    switch (message.type) {\n      .text, .binary => {\n        std.debug.print(\"received: {s}\\n\", .{message.data});\n        try client.write(message.data);\n      },\n      .ping => try client.writePong(message.data),\n      .pong => {},\n      .close => {\n        try client.close(.{});\n        break;\n      }\n    }\n  }\n}\n```\n\n### Config\nWhen creating a Client, the 2nd parameter is a configuration object:\n\n* `port` - The port to connect to. Required.\n* `host` - The host/IP address to connect to. The Host:IP value IS NOT automatically put in the header of the handshake request. Required.\n* `max_size` - Maximum incoming message size to allow. The library will dynamically allocate up to this much space per request. Default: `65536`.\n* `buffer_size` - Size of the static buffer that's available for the client to process incoming messages. While there's other overhead, the minimal memory usage of the server will be `# of active clients * buffer_size`. Default: `4096`.\n* `tls` - Whether or not to connect over TLS. Only TLS 1.3 is supported. Default: `false`.\n* `ca_bundle` - Provide a custom `std.crypto.Certificate.Bundle`. Only meaningful when `tls = true`. Default: `null`.\n\nSetting `max_size == buffer_size` is valid and will ensure that no dynamic memory allocation occurs once the connection is established.\n\nZig only supports TLS 1.3, so this library can only connect to hosts using TLS 1.3. If no `ca_bundle` is provided, the library will create a default bundle per connection.\n\n### Handshake\n`client.handshake()` takes two parameters. The first is the request path. The second is handshake configuration value:\n\n* `timeout_ms` - Timeout, in milliseconds, for the handshake. Default: `10_000` (10 seconds).\n* `headers` - Raw headers to include in the handshake. Multiple headers should be separated by by \"\\r\\n\". Many servers require a Host header. Example: `\"Host: server\\r\\nAuthorization: Something\"`. Defaul: `null`\n\n### Custom Wrapper\nIn more advanced cases, you'll likely want to wrap a `*ws.Client` in your own type and use a background read loop with \"callback\" methods. Like in the above example, you'll first want to create a client and initialize a handshake:\n\n```zig\nconst ws = @import(\"websocket\");\n\nconst Handler = struct {\n  client: ws.Client,\n\n  fn init(allocator: std.mem.Allocator) !Handler {\n    var client = try ws.Client.init(allocator, .{\n      .port = 9224,\n      .host = \"localhost\",\n    });\n    defer client.deinit();\n\n     // send the initial handshake request\n    const request_path = \"/ws\";\n    try client.handshake(request_path, .{\n      .timeout_ms = 1000,\n      .headers = \"host: localhost:9224\\r\\n\",\n    });\n\n    return .{\n      .client = client,\n    };\n  }\n  ```\n\nYou can then call `client.readLoopInNewThread()` to start a background listener. Your handler must define a `serverMessage` method:\n\n```zig\n  pub fn startLoop(self: *Handler) !void {\n    // use readLoop for a blocking version\n    const thread = try self.client.readLoopInNewThread(self);\n    thread.detach();\n  }\n\n  pub fn serverMessage(self: *Handler, data: []u8) !void {\n    // echo back to server\n    return self.client.write(data);\n  }\n}\n```\n\nWebsockets have a number of different message types. `serverMessage` only receives text and binary messages. If you care about the distinction, you can use an overload:\n\n```zig\npub fn serverMessage(self: *Handler, data: []u8, tpe: ws.MessageTextType) !void\n```\n\nwhere `tpe` will be either `.text` or `.binary`. Different callbacks are used for the other message types.\n\n#### Optional Callbacks\nIn addition to the required `serverMessage`, you can define optional callbacks.\n\n```zig\n// Guaranteed to be called exactly once when the readLoop exits\npub fn close(self: *Handler) void\n\n// If omitted, websocket.zig will automatically reply with a pong\npub fn serverPing(self: *Handler, data: []u8) !void\n\n// If omitted, websocket.zig will ignore this  message\npub fn serverPong(self: *Handler) !void\n\n// If omitted, websocket.zig will automatically reply with a close message\npub fn serverClose(self: *Handler) !void\n```\n\nYou almost certainly **do not** want to define a `serverClose` method, but instead what do define a `close` method. In your `close` callback, you should call `client.close(.{})` (and optionally pass a code and reason).\n\n## Client\nWhether you're calling `client.read()` explicitly or using `client.readLoopInNewThread()` (or `client.readLoop()`), the `client` API is the same. In both cases, the various `write` methods, as well as `close()` are thread-safe.\n\n### Writing\nIt may come as a surprise, but every variation of `write` expects a `[]u8`, not a `[]const u8`. Websocket payloads sent from a client need to be masked, which the websocket.zig library handles. It is obviously more efficient to mutate the given payload versus creating a copy. By taking a `[]u8`, applications with mutable buffers benefit from avoiding the clone. Applications that have immutable buffers will need to create a mutable clone.\n\n```zig\n// write a text message\npub fn write(self: *Client, data: []u8) !void\n\n// write a text message (same as client.write(data))\npub fn writeText(self: *Client, data: []u8) !void\n\n// write a binary message\npub fn writeBin(self: *Client, data: []u8) !void\n\n// write a ping message\npub fn writePing(self: *Client, data: []u8) !void\n\n// write a pong message\n// if you don't define a handlePong message, websocket.zig\n// will automatically answer any ping with a pong\npub fn writePong(self: *Client, data: []u8) !void\n\n// lower-level, use by all of the above\npub fn writeFrame(self: *Client, op_code: proto.OpCode, data: []u8) !void\n```\n\n### Reading\nAs seen above, most applications will either chose to call `read()` explicitly or use a `readLoop`. It is **not safe* to call `read` while the read loop is running.\n\n```zig\n// Reads 1 message. Returns null on timeout\n// Set a timeout using `client.readTimeout(ms)`\npub fn read(self: *Client) !?ws.Message\n\n\n// Starts a readloop in the calling thread. \n// `@TypeOf(handler)` must define the `serverMessage` callback\n// (and may define other optional callbacks)\npub fn readLoop(self: *Client, handler: anytype) !void\n\n// Same as `readLoop` but starts the readLoop in a new thread\npub fn readLoopInNewThread(self: *Client, h: anytype) !std.Thread\n```\n\n### Closing\nUse `try client.close(.{.code = 4000, .reason = \"bye\"})` to both send a close frame and close the connection. Noop if the connection is already known to be close. Thread safe.\n\nBoth `code` and `reason` are optional. Refer to [RFC6455](https://datatracker.ietf.org/doc/html/rfc6455#section-7.4.1) for valid codes. The `reason` must be <= 123 bytes.\n\n\n### Performance Optimization 1 - CA Bundle\nFor a high number of connections, it might be beneficial to manage our own CA bundle:\n\n```zig\n// some global data\nvar ca_bundle = std.crypto.Certificate.Bundle{}\ntry ca_bundle.rescan(allocator);\ndefer ca_bundle.deinit(allocator);\n```\n\nAnd then assign this `ca_bundle` into the the configuration's `ca_bundle` field. This way the library does not have to create and scan the installed CA certificates for each client connection.\n\n### Performance Optimization 2 - Buffer Provider\nFor a high nummber of connections a large buffer pool can be created and provided to each client:\n\n```zig\n// Create a buffer pool of 10 buffers, each being 32K\nconst buffer_provider = try websocket.bufferProvider(allocator, 10, 32768);\ndefer buffer_provider.deinit();\n\n\n// create your client(s) using the above created buffer_provider\nvar client = try websocket.connect(allocator, \"localhost\", 9001, .{\n    ...\n    .buffer_provider = buffer_provider,\n});\n```\n\nThis allows each client to have a reasonable `buffer_size` that can accomodate most messages, while having an efficient fallback for the occasional large message. When `max_size` is greater than the large buffer pool size (32K in the above example) or when all pooled buffers are used, a dynamic buffer is created.\n",
  "owner_avatar_url": "https://avatars.githubusercontent.com/u/206480?v=4",
  "releases": [],
  "owner_company": null,
  "owner_location": null,
  "owner_blog": "https://www.openmymind.net/",
  "owner_twitter_username": "karlseguin",
  "owner_followers": 2252,
  "owner_following": 3,
  "owner_created_at": "2010-02-19T04:01:58Z",
  "license": "MIT",
  "category": "library"
}