{
  "name": "zai",
  "owner": "allisoneer",
  "repo": "zai",
  "description": "Zig AI!",
  "type": "package",
  "topics": [
    "zig-package"
  ],
  "stars": 25,
  "forks": 1,
  "watchers": 2,
  "updated_at": "2025-10-20T21:46:37Z",
  "minimum_zig_version": "0.14.0",
  "readme": "# zai - a Zig AI Library\n\nzai is a flexible Zig library for interacting with various AI providers' APIs, offering a unified interface for chat completions, embeddings, and more.\n\n\n## Requirements\n\n- Zig 0.14.0\n\n## Features\n\n- Multi-provider support:\n  - OpenAI-compatible APIs (OpenAI, Together.ai, OpenRouter)\n  - Amazon Bedrock\n  - Anthropic\n  - Support coming soon for Google Vertex AI and local models via zml\n- Unified interface across providers\n- Streaming support for real-time responses\n- Provider and model registry for easy configuration\n- System prompt management and reuse across models\n- Command-line interface (CLI) for quick interactions:\n  - Stdin piping support for integrating with other Unix tools\n  - Combined prompt and context handling\n- Supports chat completions, standard completions, and embeddings\n\n## Installation\n\n1. Add zai as a dependency using `zig fetch`:\n\n```sh\n# Latest version\nzig fetch --save git+https://github.com/AdjectiveAllison/zai.git#main\n```\n\n2. Add zai as a module in your `build.zig`:\n\n```zig\nconst zai_dep = b.dependency(\"zai\", .{\n    .target = target,\n    .optimize = optimize,\n});\nconst zai_mod = zai_dep.module(\"zai\");\n\n// Add to your executable\nexe.root_module.addImport(\"zai\", zai_mod);\n```\n\n## CLI Installation\n\nTo install the zai CLI tool:\n\n```sh\nzig build cli install -Doptimize=ReleaseFast --prefix ~/.local\n```\n\n## Usage\n\n### Provider Configuration\n\nFirst, create a provider configuration. You can do this programmatically or via the CLI:\n\n```zig\nconst zai = @import(\"zai\");\n\n// OpenAI-compatible configuration\nconst provider_config = zai.ProviderConfig{ .OpenAI = .{\n    .api_key = \"your-api-key\",\n    .base_url = \"https://api.together.xyz/v1\",  // Together.ai example\n}};\n\n// Amazon Bedrock configuration\nconst bedrock_config = zai.ProviderConfig{ .AmazonBedrock = .{\n    .access_key_id = \"your-access-key\",\n    .secret_access_key = \"your-secret-key\",\n    .region = \"us-west-2\",\n}};\n\n// Anthropic configuration\nconst anthropic_config = zai.ProviderConfig{ .Anthropic = .{\n    .api_key = \"your-anthropic-api-key\",\n    .default_max_tokens = 8000, // Default max tokens limit\n}};\n```\n\n### Chat Example\n\n```zig\nconst std = @import(\"std\");\nconst zai = @import(\"zai\");\n\npub fn main() !void {\n    var gpa = std.heap.GeneralPurposeAllocator(.{}){};\n    defer _ = gpa.deinit();\n    const allocator = gpa.allocator();\n\n    // Initialize provider\n    var provider = try zai.init(allocator, provider_config);\n    defer provider.deinit();\n\n    // Set up chat messages\n    const messages = [_]zai.Message{\n        .{\n            .role = \"system\",\n            .content = \"You are a helpful assistant.\",\n        },\n        .{\n            .role = \"user\",\n            .content = \"Tell me a short joke.\",\n        },\n    };\n\n    // Configure chat options\n    const chat_options = zai.ChatRequestOptions{\n        .model = \"mistralai/Mixtral-8x7B-v0.1\",\n        .messages = &messages,\n        .temperature = 0.7,\n        .stream = true,\n    };\n\n    // Stream the response\n    try provider.chatStream(chat_options, std.io.getStdOut().writer());\n}\n```\n\n### Provider Feature Matrix\n\n| Provider       | Chat | Chat Stream | Completion | Completion Stream | Embeddings |\n|---------------|------|-------------|------------|-------------------|------------|\n| OpenAI-compatible | ✅   | ✅          | ✅         | ✅                | ✅         |\n| Amazon Bedrock    | ✅   | ✅          | ❌         | ❌                | ❌         |\n| Anthropic         | ✅   | ✅          | ❌         | ❌                | ❌         |\n| Google Vertex*    | ❌   | ❌          | ❌         | ❌                | ❌         |\n| Local (zml)*      | ❌   | ❌          | ❌         | ❌                | ❌         |\n\n\\* Coming soon\n\n## CLI Usage\n\nThe zai CLI provides commands for managing providers, models, and making API calls:\n\n```sh\n# Add a provider\nzai provider add openai --api-key \"your-key\" --base-url \"https://api.openai.com/v1\"\n\n# Add a model to a provider\nzai models add openai gpt-4 --id gpt-4-turbo-preview --chat\n\n# Manage system prompts\nzai prompt add my-system-prompt --type system --content \"You are a helpful assistant.\"\nzai prompt list\nzai prompt import another-prompt --type system --file ./prompts/my-prompt.txt\n\n# Assign a default prompt to a model\nzai models set-prompt openai gpt-4 my-system-prompt\n\n# Chat with a model (will use first provider and first model of provider by default)\nzai chat --provider openai --model gpt-4 \"Tell me a joke\"\n# same as this if openai and gpt-4 are your first provider and chat model in config.\nzai chat \"tell me a joke\"\n# The model will automatically use its default system prompt if available\n\n# Override the default system prompt for a single session\nzai chat --system-message \"You are a pirate.\" \"Tell me about sailing.\"\n\n# Pipe content from other commands or files\ncat document.txt | zai chat \"Summarize this:\"\ngit diff | zai chat \"Explain these changes:\"\n\n# Generate shell completions\nzai completions fish > ~/.config/fish/completions/zai.fish\nzai completions bash > ~/.bash_completion.d/zai\nzai completions zsh > ~/.zsh/completions/_zai\n\n# Install completions directly\nzai completions fish --install\n```\n\nSee more CLI examples and documentation by running:\n```sh\nzai --help\nzai <command> --help\n```\n\n## Examples\n\nCheck out the `examples/` directory for more detailed examples:\n- Chat using OpenAI-compatible APIs (`examples/chat_openai.zig`)\n- Chat using Amazon Bedrock (`examples/chat_bedrock.zig`)\n- Chat using Anthropic (`examples/chat_anthropic.zig`)\n- Embeddings generation (`examples/embeddings.zig`)\n- Provider registry management (`examples/registry.zig`)\n- And more!\n\n## Contributing\n\nContributions are welcome! Some areas that need work:\n- Adding tests\n- Improving CLI provider configuration workflow\n- Implementing additional providers (Google Vertex AI)\n- Local model support via zml integration\n- Documentation improvements\n\n## License\n\nzai is released under the MIT License. See the [LICENSE](LICENSE) file for details.\n",
  "owner_avatar_url": "https://avatars.githubusercontent.com/u/20910163?u=b7224bed2297ab3c8c1cd9bd2984ad1a69c3e89c&v=4",
  "releases": [],
  "owner_bio": "AI/coding/thinking",
  "owner_company": null,
  "owner_location": "San Francisco, CA",
  "owner_blog": "https://allisoneer.com",
  "owner_twitter_username": null,
  "owner_followers": 128,
  "owner_following": 123,
  "owner_created_at": "2016-08-08T16:45:59Z",
  "license": "MIT",
  "category": "library"
}